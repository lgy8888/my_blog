import{_ as n}from"./plugin-vue_export-helper-x3n3nnut.js";import{o as s,c as a,f as t}from"./app-OTaO6_y0.js";const p={},e=t(`<h1 id="rnn循环神经网络基础" tabindex="-1"><a class="header-anchor" href="#rnn循环神经网络基础" aria-hidden="true">#</a> RNN循环神经网络基础</h1><h2 id="rnn循环神经网络简介" tabindex="-1"><a class="header-anchor" href="#rnn循环神经网络简介" aria-hidden="true">#</a> RNN循环神经网络简介</h2><ul><li>RNN主要用来处理序列数据</li><li>在传统的神经网络模型中，是从输入层到隐含层到输出层，层与层之间是全连接的，每层之间的结点是无连接的 <ul><li>这种普通的神经网络无法解决很多问题，例如：无法预测句子的下一个单词是什么，一般需要用到前面的单词，因为一个句子的前后单词并不是独立的</li></ul></li></ul><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20230816203511380.png" alt="image-20230826111735682" tabindex="0" loading="lazy"><figcaption>image-20230826111735682</figcaption></figure><ul><li><p>输入x和v1 -&gt; 输出o和v2</p><ul><li>o为一般输出，v为状态输出（v代表对当前输出的理解）</li><li>v1为上一个输出的状态，v2为当前输出的状态</li></ul></li><li><p>一个RNN单元能够逐一处理句子中所有的单词</p></li><li><p>将句子中的第一个单词传递给RNN单元，RN单元生成输出(o)和中间状态(v)</p></li><li><p>该状态(v)是序列的连续含义（语境），由于在完成对整个序列的处理之前是不会输出此状态，所以称其为隐藏状态</p></li><li><p>RNN单元在处理第一个单词之后，生成了输出和隐藏状态。</p><ul><li>输出可以被训练以预测句子中的下一个字符或单词，这是大多数语言模型任务的工作方式</li><li>在文本分类的例子中，我们只考虑句子的整体含义，因此我们可以忽略每个单元生成的输出，而将重点放在隐藏状态上 <ul><li>隐藏状态的目的是保持句子的连续含义，最后的隐藏状态可以视为整个句子的整体含义，可以将其用作为分类特征</li></ul></li></ul></li><li><p>因为每个单词使用相同的RNN单元，大大减少了神经网络所需的参数两，这使得我们能够处理较大规模的小批次数据</p></li><li><p>网络参数进行学习的方式是处理序列的顺序，这是RNN的核心原则</p></li></ul><h2 id="rnncell实例" tabindex="-1"><a class="header-anchor" href="#rnncell实例" aria-hidden="true">#</a> RNNCell实例</h2><h3 id="批次处理函数" tabindex="-1"><a class="header-anchor" href="#批次处理函数" aria-hidden="true">#</a> 批次处理函数</h3><ul><li>处理文本和标签，不需要处理<code>offsets</code></li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">collate_batch</span><span class="token punctuation">(</span>batch<span class="token punctuation">)</span><span class="token punctuation">:</span>
    label_list<span class="token punctuation">,</span> text_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> <span class="token punctuation">(</span>_label<span class="token punctuation">,</span> _text<span class="token punctuation">)</span> <span class="token keyword">in</span> batch<span class="token punctuation">:</span>
        label_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>label_pipeline<span class="token punctuation">(</span>_label<span class="token punctuation">)</span><span class="token punctuation">)</span>
        text_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>text_pipeline<span class="token punctuation">(</span>_text<span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int64<span class="token punctuation">)</span><span class="token punctuation">)</span>
    label_list <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>label_list<span class="token punctuation">)</span>
    text_list <span class="token operator">=</span> rnn<span class="token punctuation">.</span>pad_sequence<span class="token punctuation">(</span>text_list<span class="token punctuation">)</span>  <span class="token comment"># 根据最长的文本对其他文本进行填充，使得每条文本的长度相同</span>
    <span class="token keyword">return</span> text_list<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> label_list<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span> <span class="token comment"># 返回的顺序需要与训练函数中的调用顺序相同</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="创建模型" tabindex="-1"><a class="header-anchor" href="#创建模型" aria-hidden="true">#</a> 创建模型</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">RNN_encode</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> embedding_dim<span class="token punctuation">,</span> hidden_unit<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>RNN_encode<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>rnn_cell <span class="token operator">=</span> nn<span class="token punctuation">.</span>RNNCell<span class="token punctuation">(</span>embedding_dim<span class="token punctuation">,</span> hidden_unit<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        batch_size <span class="token operator">=</span> inputs<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
        ht <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> hidden_unit<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>  <span class="token comment"># 初始化ht</span>
        <span class="token keyword">for</span> word <span class="token keyword">in</span> inputs<span class="token punctuation">:</span>
            ht <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn_cell<span class="token punctuation">(</span>word<span class="token punctuation">,</span> ht<span class="token punctuation">)</span>  <span class="token comment"># 迭代更新ht</span>
        <span class="token keyword">return</span> ht
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">RNN_net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> vocab_size<span class="token punctuation">,</span> embedding_dim<span class="token punctuation">,</span> hidden_unit<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>RNN_net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        <span class="token comment"># embedding层，将输入的句子中的每个单词转化为embedding_dim大小的tensor，[[···], [···],··，[···]]</span>
        self<span class="token punctuation">.</span>emb <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> embedding_dim<span class="token punctuation">)</span>
        <span class="token comment"># rnn_encode层，提取输入句子的ht(hidden state) -&gt; 整体含义</span>
        self<span class="token punctuation">.</span>rnn <span class="token operator">=</span> RNN_encode<span class="token punctuation">(</span>embedding_dim<span class="token punctuation">,</span> hidden_unit<span class="token punctuation">)</span>
        <span class="token comment"># 全连接层，用于训练二分类</span>
        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_unit<span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>emb<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="lstm网络" tabindex="-1"><a class="header-anchor" href="#lstm网络" aria-hidden="true">#</a> LSTM网络</h2><h3 id="lstm简介" tabindex="-1"><a class="header-anchor" href="#lstm简介" aria-hidden="true">#</a> LSTM简介</h3><ul><li><p>LongShortTerm（LSTM)，是一种RNN特殊类型，可以学习到长期依赖信息</p></li><li><p>LSTM的窍门在于拥有一个固定权值为1的自连接，以及一个线性激活函数，因此其局部偏导为1</p><ul><li>这样的话，误差在时间步中传递，不会消失或爆炸</li></ul></li><li><p>LSTM通过门对信息进行控制：门是一种让信息选择式通过的方法</p><ul><li>LSTM通过门可以让信息不通过，完全通过，部分通过</li></ul></li></ul><h3 id="lstm网络结构" tabindex="-1"><a class="header-anchor" href="#lstm网络结构" aria-hidden="true">#</a> LSTM网络结构</h3><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20230827162004449.png" alt="image-20230827162004449"><h3 id="lstm-cell代码实现" tabindex="-1"><a class="header-anchor" href="#lstm-cell代码实现" aria-hidden="true">#</a> LSTM Cell代码实现</h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">LSTM_encoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> embedding_dim<span class="token punctuation">,</span> hidden_unit<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>LSTM_encoder<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>rnn <span class="token operator">=</span> nn<span class="token punctuation">.</span>LSTMCell<span class="token punctuation">(</span>embedding_dim<span class="token punctuation">,</span> hidden_unit<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        batch_size <span class="token operator">=</span> inputs<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
        ht <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> hidden_unit<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>  <span class="token comment"># 初始化ht</span>
        ct <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> hidden_unit<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>  <span class="token comment"># 初始化ct</span>
        <span class="token keyword">for</span> word <span class="token keyword">in</span> inputs<span class="token punctuation">:</span>
            ht<span class="token punctuation">,</span> ct <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span>word<span class="token punctuation">,</span> <span class="token punctuation">(</span>ht<span class="token punctuation">,</span> ct<span class="token punctuation">)</span><span class="token punctuation">)</span>  <span class="token comment"># 迭代更新</span>
        <span class="token keyword">return</span> ht<span class="token punctuation">,</span> ct
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">RNN_net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> vocab_size<span class="token punctuation">,</span> embedding_dim<span class="token punctuation">,</span> hidden_unit<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>RNN_net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>emb <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> embedding_dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>rnn <span class="token operator">=</span> LSTM_encoder<span class="token punctuation">(</span>embedding_dim<span class="token punctuation">,</span> hidden_unit<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_unit<span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>emb<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
        _<span class="token punctuation">,</span> x <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> x
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="lstm网络的变体gru" tabindex="-1"><a class="header-anchor" href="#lstm网络的变体gru" aria-hidden="true">#</a> LSTM网络的变体GRU</h3><ul><li>GRU门限循环单元</li><li>与LSTM相比，GRU结构更加简单，它有一个更新门，更新门决定了内部状态与输入state状态的融合比例。GRU与LSTM网络相比，建构简单，计算少，效果相当</li></ul><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20230828155346312.png" alt="image-20230828131207281" tabindex="0" loading="lazy"><figcaption>image-20230828131207281</figcaption></figure><h3 id="gru-cell代码实现" tabindex="-1"><a class="header-anchor" href="#gru-cell代码实现" aria-hidden="true">#</a> GRU Cell代码实现</h3><ul><li>与基础<code>rnn_cell</code>类似</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">GRU_encoder</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> embedding_dim<span class="token punctuation">,</span> hidden_unit<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>GRU_encoder<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>rnn <span class="token operator">=</span> nn<span class="token punctuation">.</span>GRUCell<span class="token punctuation">(</span>embedding_dim<span class="token punctuation">,</span> hidden_unit<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        batch_size <span class="token operator">=</span> inputs<span class="token punctuation">.</span>shape<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span>
        ht <span class="token operator">=</span> torch<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span>batch_size<span class="token punctuation">,</span> hidden_unit<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>  <span class="token comment"># 初始化ht</span>
        <span class="token keyword">for</span> word <span class="token keyword">in</span> inputs<span class="token punctuation">:</span>
            ht <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span>word<span class="token punctuation">,</span> ht<span class="token punctuation">)</span>  <span class="token comment"># 迭代更新</span>
        <span class="token keyword">return</span> ht
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="lstm高阶api" tabindex="-1"><a class="header-anchor" href="#lstm高阶api" aria-hidden="true">#</a> LSTM高阶API</h3><ul><li>使用nn模块封装好的<code>nn.LSTM()</code>方法</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">LSTM_net</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> vocab_size<span class="token punctuation">,</span> embedding_dim<span class="token punctuation">,</span> hidden_unit<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>LSTM_net<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>emb <span class="token operator">=</span> nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> embedding_dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>rnn <span class="token operator">=</span> nn<span class="token punctuation">.</span>LSTM<span class="token punctuation">(</span>embedding_dim<span class="token punctuation">,</span> hidden_unit<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc1 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>hidden_unit<span class="token punctuation">,</span> <span class="token number">256</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc2 <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">256</span><span class="token punctuation">,</span> <span class="token number">2</span><span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> inputs<span class="token punctuation">)</span><span class="token punctuation">:</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>emb<span class="token punctuation">(</span>inputs<span class="token punctuation">)</span>
        o<span class="token punctuation">,</span> _ <span class="token operator">=</span> self<span class="token punctuation">.</span>rnn<span class="token punctuation">(</span>x<span class="token punctuation">)</span> <span class="token comment"># 输出：output, (h_n, c_n)， output包含了句子中每个单词的输出，(h_n, c_n)是状态输出</span>
        x <span class="token operator">=</span> F<span class="token punctuation">.</span>relu<span class="token punctuation">(</span>self<span class="token punctuation">.</span>fc1<span class="token punctuation">(</span>o<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 取最后一个节点的输出</span>
        x <span class="token operator">=</span> self<span class="token punctuation">.</span>fc2<span class="token punctuation">(</span>x<span class="token punctuation">)</span>
        <span class="token keyword">return</span> 
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,29),o=[e];function c(i,u){return s(),a("div",null,o)}const k=n(p,[["render",c],["__file","RNN循环神经网络基础.html.vue"]]);export{k as default};
