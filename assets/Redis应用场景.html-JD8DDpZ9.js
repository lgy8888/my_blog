import{_ as a}from"./plugin-vue_export-helper-x3n3nnut.js";import{o as n,c as i,f as e}from"./app-OTaO6_y0.js";const s={},l=e(`<h1 id="redis应用场景" tabindex="-1"><a class="header-anchor" href="#redis应用场景" aria-hidden="true">#</a> Redis应用场景</h1><h2 id="缓存" tabindex="-1"><a class="header-anchor" href="#缓存" aria-hidden="true">#</a> 缓存</h2><h3 id="缓存基础" tabindex="-1"><a class="header-anchor" href="#缓存基础" aria-hidden="true">#</a> 缓存基础</h3><p>Redis由于性能高效，通常可以做数据库存储的缓存，比如给MySQL当缓存</p><p>具体介绍将MySQL的热点数据存储在Redis中，通常业务都满足二八原则</p><ul><li>80%流量在20%的热点数据上</li></ul><p>所以使用缓存可以很大程度的提升系统的吞吐量</p><h4 id="两种缓存" tabindex="-1"><a class="header-anchor" href="#两种缓存" aria-hidden="true">#</a> 两种缓存</h4><p>一般缓存分为客户端缓存和服务端缓存</p><ul><li><strong>服务端缓存</strong>：服务端将数据存入Redis <ul><li>新增数据的时候顺便存入缓存</li><li>访问数据库后将数据存入缓存</li></ul></li><li><strong>客户端缓存</strong>：对服务端进行远程调用之后，将结果存在客户端 <ul><li>客户端缓存是指客户端自己实现缓存，浏览器缓存，本地缓存等</li></ul></li></ul><blockquote><p>如何选择服务端缓存还是客户端缓存</p></blockquote><p>需要分析具体瓶颈</p><p>按照通常的经验，从服务的角度来看，在目前的微服务架构下，每个服务都应该存一些热点数据，以减轻热点数据频繁请求给我们带来的压力。微服务也要有一定的互不信任原则</p><ul><li>互不信任原则：为了确保微服务之间的独立性和健壮性</li></ul><h4 id="缓存的几种模式" tabindex="-1"><a class="header-anchor" href="#缓存的几种模式" aria-hidden="true">#</a> 缓存的几种模式</h4><ul><li>Cache-Aside Pattern：旁路缓存模式</li><li>Read Through Cache Pattern：读穿透模式</li><li>Write Through Cache Pattern：写穿透模式</li><li>Write Behind Pattern (Write Back)：异步缓存写入模式</li></ul><h4 id="旁路缓存-cache-aside" tabindex="-1"><a class="header-anchor" href="#旁路缓存-cache-aside" aria-hidden="true">#</a> 旁路缓存(cache-aside)</h4><p>将Redis作为MySQL的旁路，直接和缓存进行交互</p><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/6e3db3ba2f829ddc14237f5c7c00e7ce-20230309232338149.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p><strong>读操作</strong></p><p>应用服务收到查询请求之后，先查询数据是否在缓存上</p><ul><li>如果<strong>在，就用缓存数据直接打包返回</strong></li><li>如果<strong>不在，就去数据库访问</strong>，从数据库查询，并放到缓存中</li></ul><p>业务有需要还可以预先加载数据到缓存中（缓存预热）</p><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20231120193814176.png" alt="image-20231120193814176" tabindex="0" loading="lazy"><figcaption>image-20231120193814176</figcaption></figure><p><strong>写操作</strong></p><p>在进行写操作的时候，旁路缓存模式一般会<strong>先更新数据库，然后直接删除缓存</strong></p><blockquote><p>为什么不用更新而是删除呢？</p></blockquote><p>更新比删除更容易造成<strong>时序性问题</strong></p><p>thread1更新mysql为5 -&gt; thread2更新mysql为3 -&gt; thread2更新缓存为3 -&gt; thread1更新缓存为5</p><p>最终正确的数据因为时序性被覆盖了</p><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20231120193928210.png" alt="image-20231120193928210" tabindex="0" loading="lazy"><figcaption>image-20231120193928210</figcaption></figure><p><strong>旁路缓存适合用于读多写少的场景</strong>，比如用户信息，新闻报道等，一但写入缓存，一般不会进行更改，该模式的缺点是可能会出现缓存和数据库不一致的问题</p><h4 id="读穿透-read-through" tabindex="-1"><a class="header-anchor" href="#读穿透-read-through" aria-hidden="true">#</a> 读穿透(Read Through)</h4><p>本质是<strong>将旁路缓存的读操作封装成一个服务</strong>，对外提供接口调用，业务只需要调用接口</p><p>和旁路缓存的主要区别在于：应用服务不再与缓存直接交互，而是直接访问数据服务</p><p>数据服务可以理解为一个代理，即单独起这么个服务，用它来访问数据库和缓存，作为使用者来看，不知道里面到底有没有缓存，数据服务会根据情况来查询缓存或者数据库</p><p><strong>读穿透的优缺点</strong></p><ul><li>优点：缓存对业务透明，业务只需要调用接口，业务代码更加整洁</li><li>缺点：缓存命中时性能不如旁路缓存，因为会多一次服务调用</li></ul><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20231120204218797.png" alt="image-20231120204218797" tabindex="0" loading="lazy"><figcaption>image-20231120204218797</figcaption></figure><h4 id="写穿透-write-through" tabindex="-1"><a class="header-anchor" href="#写穿透-write-through" aria-hidden="true">#</a> 写穿透(Write Through)</h4><p>本质是<strong>对旁路缓存的写操作稍作修改后封装成一个服务</strong></p><p>具体区别在于：<strong>旁路缓存是修改数据后删除对应缓存，写穿透是修改数据后同步修改缓存</strong></p><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20231120204523516.png" alt="image-20231120204523516" tabindex="0" loading="lazy"><figcaption>image-20231120204523516</figcaption></figure><p>一般写穿透会搭配读穿透一起使用</p><p>写穿透的潜在使用场景是银行系统</p><ul><li>对缓存及时性要求更高（写入就加载了缓存，当然这种模式可能会导致时序性问题）</li><li>不能忍受数据丢失（相对于write-behind来说）和数据不一致，旁路缓存也是如此</li></ul><h4 id="read-through-write-through" tabindex="-1"><a class="header-anchor" href="#read-through-write-through" aria-hidden="true">#</a> Read Through/Write Through</h4><p>读穿透和写穿透结合</p><p>当有数据更新的时候，先查询要写入的数据在缓存中是否已经存在：</p><ul><li>如果缓存中数据已经存在，则更新缓存中的数据，并且由缓存组件同步更新到数据库中，然后缓存组件告知应用程序更新完成。</li><li>如果缓存中数据不存在，直接更新数据库，然后返回</li></ul><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/WriteThrough.jpg" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>Read Through/Write Through 策略的特点是由缓存节点而非应用程序来和数据库打交道，在我们开发过程中相比 Cache Aside 策略要少见一些，原因是我们经常使用的分布式缓存组件，无论是 Memcached 还是 Redis 都不提供写入数据库和自动加载数据库中的数据的功能。而我们在使用本地缓存的时候可以考虑使用这种策略。</p><h4 id="异步缓存写入-write-behind-write-back" tabindex="-1"><a class="header-anchor" href="#异步缓存写入-write-behind-write-back" aria-hidden="true">#</a> 异步缓存写入(Write Behind)(Write Back)</h4><p>write-behind和write-through的异同</p><ul><li>相同点在于写入时候会更新数据库，也会更新缓存</li><li>不同点在于write-through会把数据立即写进数据库中，然后些缓存，安全性极高，而write-behind是先写缓存，然后异步把数据一起写入数据库，这个异步写操作是write-behind的最大特点</li></ul><p>这种模式下，数据库的写操作可以用不同的方式实现，不同的方式可以根据业务情况结合</p><ul><li>一种是时间上的灵活性：收集写操作并在某一时间点（比如数据库负载低的情况下）慢慢写入</li><li>一种是合并几个写操作称为一个批量操作，一起批量写入</li></ul><p>异步操作极大的降低了请求延迟并减轻了数据库的负担</p><p>代价是安全性不够</p><blockquote><p>先写入Redis，跟新操作先放在存储服务内存中，但是还没有异步写入数据库之前，存储服务崩溃了，那么数据也就丢失了</p></blockquote><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20231120211822402.png" alt="image-20231120211822402" tabindex="0" loading="lazy"><figcaption>image-20231120211822402</figcaption></figure><h4 id="如何选择" tabindex="-1"><a class="header-anchor" href="#如何选择" aria-hidden="true">#</a> 如何选择</h4><p>实际开发中，Redsi和MySQL都用的是旁路缓存模式，其他几种应用不了</p><h3 id="缓存异常" tabindex="-1"><a class="header-anchor" href="#缓存异常" aria-hidden="true">#</a> 缓存异常</h3><p>引入缓存，就会有<strong>缓存异常的三个问题，分别是缓存雪崩，缓存击穿和缓存穿透</strong></p><h4 id="缓存雪崩" tabindex="-1"><a class="header-anchor" href="#缓存雪崩" aria-hidden="true">#</a> 缓存雪崩</h4><p><strong>通常为了保证缓存中数据与数据库数据的一致性，会给Redis的数据设置过期时间</strong></p><p>当缓存过期后，用户访问的数据如果不在缓存中，业务系统需要重新生成缓存，因此就会访问数据库，并将数据更新到Redis中，这样后续的请求都能直接命中缓存</p><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/e2b8d2eb5536aa71664772457792ec40-20230309232851699.png" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><p><strong><u>当大量缓存数在同一时间过期（失效），或者Redis故障宕机时，如果此时有大量的用户请求，都无法在Redis中处理，于是全部请求就会直接访问数据库，从而导致数据库压力骤增</u></strong>，严重的会导致数据库宕机，形成一系列的连锁反应，造成系统崩溃，这就是缓存雪崩</p><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/717343a0da7a1b05edab1d1cdf8f28e5.png" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><p>发生缓存雪崩有两个原因：</p><ul><li><strong>大量数据同时过期；</strong></li><li><strong>Redis 故障宕机；</strong></li></ul><h5 id="大量数据同时过期" tabindex="-1"><a class="header-anchor" href="#大量数据同时过期" aria-hidden="true">#</a> 大量数据同时过期</h5><p>针对大量数据同时过期而引发的缓存雪崩问题，常见的应对方法</p><ul><li><strong>均匀设置过期时间</strong> —— TTL加随机数</li><li><strong>互斥锁</strong> —— 同一时间只能有一个请求去访问数据库</li><li><strong>后台更新缓存</strong> —— 业务只读缓存且永久有效，后台定期更新缓存</li><li><strong>多级缓存</strong> —— 设置多级缓存，不止Redis</li></ul><h6 id="均匀设置过期时间" tabindex="-1"><a class="header-anchor" href="#均匀设置过期时间" aria-hidden="true">#</a> 均匀设置过期时间</h6><p>如果要给缓存数据设置过期时间，应该避免将大量的数据设置成同一个过期时间。我们可以在对缓存数据设置过期时间时，<strong>给这些数据的过期时间加上一个随机数</strong>，这样就保证数据不会在同一时间过期。</p><h6 id="互斥锁" tabindex="-1"><a class="header-anchor" href="#互斥锁" aria-hidden="true">#</a> 互斥锁</h6><p>当业务线程在处理用户请求时，<strong><u>如果发现访问的数据不在 Redis 里，就加个互斥锁，保证同一时间内只有一个请求来构建缓存</u></strong></p><ul><li>构建缓存：从数据库读取数据，再将数据更新到 Redis 里</li></ul><p>缓存构建完成后再释放锁。未能获取互斥锁的请求，要么等待锁释放后重新读取缓存，要么就返回空值或者默认值。</p><p><strong>实现互斥锁的时候，需要设置超时时间</strong>，不然第一个请求拿到了锁，然后这个请求发生了某种意外而一直阻塞，一直不释放锁，这时其他请求也一直拿不到锁，整个系统就会出现无响应的现象。</p><h6 id="后台更新缓存" tabindex="-1"><a class="header-anchor" href="#后台更新缓存" aria-hidden="true">#</a> 后台更新缓存</h6><p>业务线程不负责更新缓存，缓存也不设有效期，<strong><u>让缓存“永久有效”，并将更新缓存的工作交由后台线程定时更新</u></strong>。</p><p>事实上，缓存数据不设置有效期，并不是意味着数据一直能在内存里，因为<strong>当系统内存紧张的时候，有些缓存数据会被“淘汰”</strong>，而在缓存被“淘汰”到下一次后台定时更新缓存的这段时间内，业务线程读取缓存失败就返回空值，业务的视角就以为是数据丢失了。</p><blockquote><p>旁路缓存是：查缓存，查不到就查数据库，查完数据库回来构建缓存</p><p>后台更新缓存是：查缓存，查不到就返回空，并且发消息进消息队列通知后台线程要更新缓存</p></blockquote><ul><li><strong>后台线程不仅负责定时更新缓存，而且也负责频繁地检测缓存是否有效</strong><ul><li>检测到缓存失效了，原因可能是系统紧张而被淘汰的，于是就要马上从数据库读取数据，并更新到缓存。</li><li>这种方式的检测时间间隔不能太长，太长也导致用户获取的数据是一个空值而不是真正的数据，所以检测的间隔最好是毫秒级的，但是总归是有个间隔时间，用户体验一般。</li></ul></li><li><strong>由业务线程告诉后台缓存失效，后台收到消息后再判断是否更新缓存</strong><ul><li>在业务线程发现缓存数据失效后（缓存数据被淘汰），<strong>通过消息队列发送一条消息通知后台线程更新缓存</strong>，后台线程收到消息后，在更新缓存前可以判断缓存是否存在，存在就不执行更新缓存操作；不存在就读取数据库数据，并将数据加载到缓存。这种方式相比第一种方式缓存的更新会更及时，用户体验也比较好。</li><li>在业务刚上线的时候，我们最好提前把数据缓起来，而不是等待用户访问才来触发缓存构建，这就是所谓的<strong>缓存预热</strong>，后台更新缓存的机制刚好也适合干这个事情。</li></ul></li></ul><h6 id="多级缓存" tabindex="-1"><a class="header-anchor" href="#多级缓存" aria-hidden="true">#</a> 多级缓存</h6><p>可以在Redis上面设置浏览器缓存，反向代理缓存(nginx)</p><ul><li>浏览器缓存 -&gt; nginx缓存 -&gt; redis缓存 -&gt; DB</li></ul><h5 id="redis故障宕机" tabindex="-1"><a class="header-anchor" href="#redis故障宕机" aria-hidden="true">#</a> Redis故障宕机</h5><p>针对Redis故障宕机引发的缓存雪崩问题，常见的应对方法有两种</p><ul><li>服务熔断或请求限流</li><li>构建Redis缓存高可靠集群</li></ul><h6 id="服务熔断或请求限流" tabindex="-1"><a class="header-anchor" href="#服务熔断或请求限流" aria-hidden="true">#</a> 服务熔断或请求限流</h6><p><strong>服务熔断</strong>：暂停业务应用对缓存服务的访问，直接返回错误，不用再继续访问数据库，降低对数据库的访问压力</p><ul><li>等到Redis恢复正常后，再允许业务应用访问缓存服务</li></ul><p>服务熔断机制是保护数据库的正常允许，但是暂停了业务应用访问缓存服务，系统全部业务都无法正常工作</p><p><strong>请求限流</strong>：只将少部分请求发送到数据库进行处理，再多的请求就再入口直接拒绝服务</p><ul><li>等到Reids恢复正常并且把缓存预热完毕，再解除请求限流的机制</li></ul><h6 id="构建redis高可靠集群" tabindex="-1"><a class="header-anchor" href="#构建redis高可靠集群" aria-hidden="true">#</a> 构建Redis高可靠集群</h6><p>服务熔断和请求限流机制是缓存雪崩后发生的应对方案，我们最好通过主从节点的方式构建Redis缓存高可靠集群</p><p>如果Redis缓存的主节点故障宕机，从节点可以切换为主节点，继续提供缓存服务，避免由于Redis故障宕机而导致的缓存雪崩</p><h4 id="缓存击穿" tabindex="-1"><a class="header-anchor" href="#缓存击穿" aria-hidden="true">#</a> 缓存击穿</h4><p>业务中通常会有几个数据被频繁访问，比如秒杀活动，这些被频繁访问的数据被称为热点数据</p><p><strong><u>如果缓存中的某个热点数据过期了，此时大量的请求访问了该热点数据，就无法从缓存中读取，直接访问数据库，数据库就很容易被高并发的请求冲垮</u></strong>，这就是缓存击穿的问题</p><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/acb5f4e7ef24a524a53c39eb016f63d4-20230309232840753.png" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><blockquote><p>缓存击穿可以认为是缓存雪崩的一个子集</p></blockquote><h5 id="解决方案" tabindex="-1"><a class="header-anchor" href="#解决方案" aria-hidden="true">#</a> 解决方案</h5><ul><li><strong>互斥锁</strong>：保证同一时间只有一个业务线程构建缓存 <ul><li>未能获取到互斥锁的请求，要么等待所锁释放后重新读取缓存，要么返回空值或默认值</li></ul></li><li><strong>后台更新缓存</strong>：不给热点Key设置过期时间，后台异步更新缓存 <ul><li>或者在热点key准备要过期前，提前通知后台线程更新缓存以及重新设置过期时间</li></ul></li><li><strong>热点数据续期</strong>：持续访问的数据可以不断续期，避免因为过期失效而被击穿</li><li><strong>逻辑过期</strong><ul><li>之所以会出现缓存击穿，主要原因是在于我们对key设置了过期时间，假设我们不设置过期时间，而是通过添加一个字段&quot;expire&quot;</li><li>这个字段通常是我们当前时间再加上一段时间形成的过期时间，需要人来维护</li><li>避免不设置过期时间，导致数据一直占用内存，可以采用逻辑过期方案。一般是在做活动的时候就会用到这种方式，活动结束的时候再把手动添加的这个字段移除。</li><li>缺点：在构建完缓存之前，返回的都是脏数据。</li><li>特点：使用异步线程构建缓存</li></ul></li></ul><h4 id="缓存穿透" tabindex="-1"><a class="header-anchor" href="#缓存穿透" aria-hidden="true">#</a> 缓存穿透</h4><p>当发生缓存雪崩或击穿时，数据库中还是保存了应用要访问的数据，一旦缓存恢复相对应的数据，就可以减轻数据库的压力，而缓存穿透就不一样了。</p><p><strong><u>当用户访问的数据，既不在缓存中，也不在数据库中，导致请求在访问缓存时，发现缓存缺失，再去访问数据库时，发现数据库中也没有要访问的数据，没办法构建缓存数据，来服务后续的请求。当有大量这样的请求到来时，数据库的压力骤增</u></strong>，这就是缓存穿透的问题。</p><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/b7031182f770a7a5b3c82eaf749f53b0-20230309232834574.png" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><p>缓存穿透的发生一般有这两种情况：</p><ul><li><strong>业务误操作</strong>，缓存中的数据和数据库中的数据都被误删除了，所以导致缓存和数据库中都没有数据；</li><li><strong>非法请求</strong>，故意大量访问某些读取不存在数据的业务；</li></ul><p>应对缓存穿透的方案，常见的方案有三种。</p><ul><li>第一种方案，<strong>非法请求的限制</strong>；</li><li>第二种方案，<strong>缓存空值或者默认值</strong>；</li><li>第三种方案，使用<strong>布隆过滤器</strong>快速判断数据是否存在，避免通过查询数据库来判断数据是否存在；</li></ul><h5 id="限制非法请求" tabindex="-1"><a class="header-anchor" href="#限制非法请求" aria-hidden="true">#</a> 限制非法请求</h5><p>当有大量恶意请求访问不存在的数据的时候，也会发生缓存穿透，因此在 API 入口处我们要判断求请求参数是否合理，请求参数是否含有非法值、请求字段是否存在，如果判断出是恶意请求就直接返回错误，避免进一步访问缓存和数据库。</p><h5 id="缓存空值或者默认值" tabindex="-1"><a class="header-anchor" href="#缓存空值或者默认值" aria-hidden="true">#</a> 缓存空值或者默认值</h5><p>线上业务发现缓存穿透的现象时，可以针对查询的数据，在缓存中设置一个空值或者默认值，这样后续请求就可以从缓存中读取到控制或者默认值，返回给应用， 就不会继续查询数据库了</p><p>一般设置的空值需要加个过期时间，这个过期时间不能太久，一般30s左右</p><blockquote><p>如果太久，这个key后面赋值了，会有很长的一段时间查询不到这个值</p></blockquote><h5 id="布隆过滤器判断数据是否存在" tabindex="-1"><a class="header-anchor" href="#布隆过滤器判断数据是否存在" aria-hidden="true">#</a> 布隆过滤器判断数据是否存在</h5><p>我们可以在写入数据库数据时，使用布隆过滤器做个标记，然后在用户请求到来时，业务线程确认缓存失效后，可以通过查询布隆过滤器快速判断数据是否存在，如果不存在，就不用通过查询数据库来判断数据是否存在。</p><p>即使发生了缓存穿透，大量请求只会查询 Redis 和布隆过滤器，而不会查询数据库，保证了数据库能正常运行，Redis 自身也是支持布隆过滤器的。</p><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20231120213056017.png" alt="image-20231120213056017" tabindex="0" loading="lazy"><figcaption>image-20231120213056017</figcaption></figure><h6 id="布隆过滤器" tabindex="-1"><a class="header-anchor" href="#布隆过滤器" aria-hidden="true">#</a> 布隆过滤器</h6><p>布隆过滤器是用来查询数据一定不存在或可能存在</p><ul><li>布隆过滤器说不存在，数据库中就一定没用</li><li>布隆过滤器说存在，数据库中不一定有</li></ul><p>布隆过滤器由「初始值都为 0 的位图数组」和「 N 个哈希函数」两部分组成。</p><p>当我们在写入数据库数据时，在布隆过滤器里做个标记，这样下次查询数据是否在数据库时，只需要查询布隆过滤器，如果查询到数据没有被标记，说明不在数据库中。</p><p>布隆过滤器会通过 3 个操作完成标记：</p><ul><li>第一步，使用 N 个哈希函数分别对数据做哈希计算，得到 N 个哈希值；</li><li>第二步，将第一步得到的 N 个哈希值对位图数组的长度取模，得到每个哈希值在位图数组的对应位置。</li><li>第三步，将每个哈希值在位图数组的对应位置的值设置为 1；</li></ul><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/86b0046c2622b2c4bda697f9bc0f5b28.png" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><ul><li>在数据库写入数据 x 后</li><li>x 会被 3 个哈希函数分别计算出 3 个哈希值</li><li>对这 3 个哈希值对 8 取模，假设取模的结果为 1、4、6</li><li>把位图数组的第 1、4、6 位置的值设置为 1</li><li><strong>当应用要查询数据 x 是否数据库时，通过布隆过滤器只要查到位图数组的第 1、4、6 位置的值是否全为 1，只要有一个为 0，就认为数据 x 不在数据库中</strong>。</li></ul><p>布隆过滤器由于是基于哈希函数实现查找的，高效查找的同时<strong>存在哈希冲突的可能性</strong></p><p>比如数据 x 和数据 y 可能都落在第 1、4、6 位置，而事实上，可能数据库中并不存在数据 y，存在误判的情况。</p><p>所以，<strong>查询布隆过滤器说数据存在，并不一定证明数据库中存在这个数据，但是<u>查询到数据不存在，数据库中一定就不存在这个数据</u></strong>。</p><h4 id="缓存异常总结" tabindex="-1"><a class="header-anchor" href="#缓存异常总结" aria-hidden="true">#</a> 缓存异常总结</h4><table><thead><tr><th style="text-align:left;">缓存异常</th><th style="text-align:left;">产生原因</th><th>应对方案</th></tr></thead><tbody><tr><td style="text-align:left;">缓存雪崩</td><td style="text-align:left;">大量数据同时过期</td><td>均匀设置过期时间：避免同一时间过期</td></tr><tr><td style="text-align:left;"></td><td style="text-align:left;"></td><td>互斥锁：保证同一时间只有一个应用在构建缓存</td></tr><tr><td style="text-align:left;"></td><td style="text-align:left;"></td><td>双key策略：主key设置过期时间，备key永久，主key过期时返回备key内容</td></tr><tr><td style="text-align:left;"></td><td style="text-align:left;"></td><td>后台更新缓存：定时更新 / 消息队列通知更新</td></tr><tr><td style="text-align:left;"></td><td style="text-align:left;"></td><td>多级缓存：浏览器、反向代理(nginx)……</td></tr><tr><td style="text-align:left;"></td><td style="text-align:left;">Redis故障宕机</td><td>服务熔断：暂停业务应用对缓存服务的访问，直接返回错误</td></tr><tr><td style="text-align:left;"></td><td style="text-align:left;"></td><td>请求限流：只允许少部分的请求访问数据库</td></tr><tr><td style="text-align:left;"></td><td style="text-align:left;"></td><td>构建Redis缓存高可靠集群：主从模式/哨兵机制/分片集群</td></tr><tr><td style="text-align:left;">缓存击穿</td><td style="text-align:left;">热点key过期</td><td>互斥锁：保证同一时间只有一个应用在构建缓存</td></tr><tr><td style="text-align:left;"></td><td style="text-align:left;"></td><td>后台更新缓存：定时更新 / 消息队列通知更新</td></tr><tr><td style="text-align:left;"></td><td style="text-align:left;"></td><td>热点数据续期：持续访问的数据可以不断续期，避免因为过期失效而被击穿</td></tr><tr><td style="text-align:left;"></td><td style="text-align:left;"></td><td>逻辑过期：key不设置过期，给个新属性代表其过期时间</td></tr><tr><td style="text-align:left;">缓存穿透</td><td style="text-align:left;">访问的数据既不在缓存也不在数据库</td><td>限制非法请求：在API入口进行检查</td></tr><tr><td style="text-align:left;"></td><td style="text-align:left;"></td><td>缓存空值或者默认值：给请求的值缓存一个空值或者默认值</td></tr><tr><td style="text-align:left;"></td><td style="text-align:left;"></td><td>使用布隆过滤器判断数据是否存在</td></tr></tbody></table><h3 id="缓存一致性" tabindex="-1"><a class="header-anchor" href="#缓存一致性" aria-hidden="true">#</a> 缓存一致性</h3><h4 id="写写并发" tabindex="-1"><a class="header-anchor" href="#写写并发" aria-hidden="true">#</a> 写写并发</h4><ol><li><strong>先更新数据库再更新缓存</strong></li></ol><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/8febac10b14bed16cb96d1d944cd08da.png" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><p>结果：缓存为1，数据库为2，数据不一致</p><ol start="2"><li><strong>先更新缓存再更新数据库</strong></li></ol><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/454a8228a6549176ad7e0484fba3c92b.png" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><p>结果：缓存为2，数据库为1，数据不一致</p><p><strong>写写并发场景中，无论是「先更新数据库，再更新缓存」，还是「先更新缓存，再更新数据库」，这两个方案都存在并发问题，当两个请求并发更新同一条数据的时候，可能会出现缓存和数据库中的数据不一致的现象</strong>。</p><h5 id="解决办法" tabindex="-1"><a class="header-anchor" href="#解决办法" aria-hidden="true">#</a> 解决办法</h5><ul><li>使用旁路缓存模式的写策略——<strong>改为先更新数据库再删除缓存</strong></li><li><strong>如果我们的业务对缓存命中率有很高的要求，需要采用「更新数据库 + 更新缓存」的方案</strong><ul><li>在更新缓存前先加个<strong>分布式锁</strong>，保证<strong>同一时间只运行一个请求更新缓存</strong>，就会不会产生并发问题了，当然引入了锁后，对于写入的性能就会带来影响。</li><li>在更新完缓存时，给缓存加上较短的<strong>过期时间</strong>，这样即时出现缓存不一致的情况，缓存的数据也会很快过期，对业务还是能接受的</li></ul></li></ul><h4 id="读写并发" tabindex="-1"><a class="header-anchor" href="#读写并发" aria-hidden="true">#</a> 读写并发</h4><ol><li><strong>先删除缓存再更新数据库</strong></li></ol><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/cc208c2931b4e889d1a58cb655537767.png" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><p>结果：缓存为20，数据库为21，数据不一致</p><ol start="2"><li><strong>先更新数据库再删除缓存</strong></li></ol><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/1cc7401143e79383ead96582ac11b615.png" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><p>结果：缓存为20，数据库为21，数据不一致</p><p><strong>读写并发场景中，无论是「先更新数据库，再删除缓存」，还是「先删除缓存，再更新数据库」，这两个方案都存在并发问题，当两个请求并发更新同一条数据的时候，可能会出现缓存和数据库中的数据不一致的现象</strong>。</p><h5 id="解决方法" tabindex="-1"><a class="header-anchor" href="#解决方法" aria-hidden="true">#</a> 解决方法</h5><p><strong>在实际中，这个问题出现的概率并不高</strong>。</p><p><strong>因为缓存的写入通常要远远快于数据库的写入</strong>，所以在实际中很难出现请求 B 已经更新了数据库并且删除了缓存，请求 A 才更新完缓存的情况。</p><p>一旦请求 A 早于请求 B 删除缓存之前更新了缓存，那么接下来的请求就会因为缓存不命中而从数据库中重新读取数据，所以不会出现这种不一致的情况。</p><p>所以，<strong><u>「先更新数据库 + 再删除缓存」的方案，是可以保证数据一致性的</u></strong>。</p><p>实际生产中还需要给<strong>缓存设置过期时间兜底</strong>，就算真的发生了数据不一致，有过期时间兜底最后也会数据也能一致</p><h4 id="如果缓存删除失败" tabindex="-1"><a class="header-anchor" href="#如果缓存删除失败" aria-hidden="true">#</a> 如果缓存删除失败</h4><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/2a2ea2854bbc3ae8ae86d7da45fa32ee.png" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><p>后续有访问数据 X 的请求，会先在 Redis 中查询，因为缓存并没有 诶删除，所以会缓存命中，但是读到的却是旧值 1</p><h5 id="解决办法-1" tabindex="-1"><a class="header-anchor" href="#解决办法-1" aria-hidden="true">#</a> 解决办法</h5><h6 id="重试机制" tabindex="-1"><a class="header-anchor" href="#重试机制" aria-hidden="true">#</a> 重试机制</h6><p>引入<strong>消息队列</strong>，将第二个操作（删除缓存）要操作的数据加入到消息队列，由消费者来操作数据。</p><ul><li>如果应用<strong>删除缓存失败</strong>，可以从消息队列中重新读取数据，然后再次删除缓存，这个就是<strong>重试机制</strong>。当然，如果重试超过的一定次数，还是没有成功，我们就需要向业务层发送报错信息了。</li><li>如果<strong>删除缓存成功</strong>，就要把数据从消息队列中移除，避免重复操作，否则就继续重试</li></ul><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/a4440f0d572612e0832b903e4a62bd2b.png" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><h6 id="订阅mysql-binlog-再操作缓存" tabindex="-1"><a class="header-anchor" href="#订阅mysql-binlog-再操作缓存" aria-hidden="true">#</a> 订阅MySQL binlog，再操作缓存</h6><p>「<strong>先更新数据库，再删缓存</strong>」的策略的第一步是更新数据库，那么更新数据库成功，就会产生一条变更日志，记录在 binlog 里。</p><p>于是我们就可以通过订阅 binlog 日志，拿到具体要操作的数据，然后再执行缓存删除，阿里巴巴开源的 Canal 中间件就是基于这个实现的。</p><p>Canal 模拟 MySQL 主从复制的交互协议，把自己伪装成一个 MySQL 的从节点，向 MySQL 主节点发送 dump 请求，MySQL 收到请求后，就会开始推送 Binlog 给 Canal，Canal 解析 Binlog 字节流之后，转换为便于读取的结构化数据，供下游程序订阅使用。</p><ul><li><strong><u>Canal最大的作用其实是用来把删除缓存的逻辑和业务系统解耦</u></strong></li><li>Redis从Canal获取到更新数据的日志之后，需要实现逻辑去维护删除逻辑的成功与否</li></ul><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/2ee2280e9f59b6b4879ebdec6eb0cf52.png" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><h4 id="延时双删" tabindex="-1"><a class="header-anchor" href="#延时双删" aria-hidden="true">#</a> 延时双删</h4><ul><li>其实就是在更新数据库之前，先删除一次缓存，在更新数据库之后，等待一段时间，在删除一次缓存。</li><li>这个睡眠时间是个<strong>玄学</strong>，很难评估出来，所以这个方案也只是<strong>尽可能</strong>保证一致性而已，极端情况下，依然也会出现缓存不一致的现象。</li></ul><p><strong>延迟双删伪代码</strong></p><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment"># 删除缓存</span>
redis.delKey<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment"># 更新数据库</span>
db.update<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment"># 睡眠</span>
Thread.sleep<span class="token punctuation">(</span>n<span class="token punctuation">)</span><span class="token punctuation">;</span>
<span class="token comment"># 删除缓存</span>
redis.delKey<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h5 id="为什么要双删" tabindex="-1"><a class="header-anchor" href="#为什么要双删" aria-hidden="true">#</a> 为什么要双删？</h5><blockquote><p>是为了弥补只删除一次的缺陷</p></blockquote><ul><li>如果先删除缓存再更新数据库，在删除缓存之后，更新数据库之前，数据请求未命中，会缓存旧的数据，第二次删除解决的就是这个问题</li><li>如果先更新数据库再删除缓存，那么更新完数据库之后，如果还没来得及删除缓存，缓存命中的是旧数据，第一次删除解决的就是这个问题</li></ul><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/1698590106755-e8d61748-c404-47e2-af9f-512ec5c2c242.jpeg" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/1698590685263-444ce79d-4e66-41e0-ab57-42a42245da77.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><h5 id="为什么要延时" tabindex="-1"><a class="header-anchor" href="#为什么要延时" aria-hidden="true">#</a> 为什么要延时</h5><ul><li>为了确保在第一次删除之后，如果有查询到旧数据的请求，能够在第二次删除之前把旧的数据先写到缓存中，第二次删除才有意义，否则删除空缓存，然后又缓存入了旧数据</li><li>解决的其实就是上面提到的先更新数据库，在删除缓存，出现的小概率不一致性的情况</li></ul><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/1694830495587-cac7d07d-42a8-4977-adc2-07ae0bdad4b9.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/1694830524024-fa907652-ebe3-4fcb-8c7e-a1cd6ab13be0.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><h4 id="方案总结" tabindex="-1"><a class="header-anchor" href="#方案总结" aria-hidden="true">#</a> 方案总结</h4><p>保证缓存和数据库数据一致性的四种方案</p><ol><li>等待过期</li></ol><ul><li><p>优点：</p><ul><li><p>redis原生接口，开发成本低，易于实现；</p></li><li><p>管理成本低，出问题的概率会比较小。</p></li></ul></li></ul><ul><li>不足： <ul><li>完全依赖过期时间，时间太短容易造成缓存频繁失效，太长容易有较长时间不一致，对编程者的业务能力，有一定要求。</li></ul></li></ul><ol start="2"><li>主动删除</li></ol><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/640.jpeg" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><ul><li><p>优点：</p><ul><li><p>相对方案一，达成最终一致性的延迟更小；</p></li><li><p>实现成本较低，只是在方案一的基础上，增加了删除逻辑。</p></li></ul></li><li><p>不足：</p><ul><li><p>如果更新mysql成功，删除redis却失败，就退化到了方案一；</p></li><li><p>在高并发场景，业务server需要和mysql、redis同时进行连接，这样是损耗双倍的连接资源，容易造成连接数过多的问题。</p></li></ul></li></ul><ol start="3"><li><p>主动更新</p><ol><li>消息投递</li></ol><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/640-17005779426854.jpeg" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><ul><li><p>优点：</p><ul><li><p>使用消息队列，就相当于将请求投递至信箱，只要投递成功即完成任务，不用关心结果，实现了进一步解耦；</p></li><li><p>消息队列本身具有可靠性，在投递成功的前提下，通过手动提交等手段去消费，可以保证更新操作至少在redis中执行一次。</p></li></ul></li><li><p>不足：</p><ul><li><p>有时序性问题。</p><blockquote><p>两台业务服务器在同一时间发出a = 1和a = 5两条请求，若mysql中先执行a=1再执行a=5，则mysql中a的值最终为5；但由于网络传输本身有延迟，所以无法保证两条请求谁先进入消息队列，最终redis的结果可能是1也可能是5，如果是1，mysql和redis中的数据就会产生不一致；</p></blockquote></li><li><p>引入了消息队列，同时要增加消费服务，成本较高；</p></li><li><p>依旧有消耗更多客户端连接数的问题。</p></li></ul></li></ul><ol start="2"><li>订阅日志</li></ol><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/640-17005779897756.jpeg" alt="图片" tabindex="0" loading="lazy"><figcaption>图片</figcaption></figure><ul><li><p>优点：</p><ul><li><p>在同步服务压力不大情况下，延迟较低；</p></li><li><p>和业务完全解耦，在更新mysql时，不需要做额外操作；</p></li><li><p>解决了时序性问题，可靠性强。</p></li></ul></li><li><p>缺点：</p><ul><li><p>要单独搭建一个同步服务，并且引入binlog同步机制，成本较大；</p></li><li><p>同步服务如果压力比较大，或者崩溃了，那么在较长时间内，redis中都是老旧数据。</p></li></ul></li></ul></li></ol><h4 id="方案选型" tabindex="-1"><a class="header-anchor" href="#方案选型" aria-hidden="true">#</a> <strong>方案选型</strong></h4><ol><li>首先确认产品上对延迟性的要求，如果要求极高，且数据有可能变化，别用缓存。</li><li>通常来说，方案1就够了。牛牛咨询过4、5个团队，基本都是用方案1，因为使用缓存方案，通常是读多写少场景，同时业务上对延迟具有一定的包容性。方案1虽然有一定延时，但比较实用。</li><li>如果想增加更新时的即时性，就选择方案2，不过一定要注意，针对redis老数据的删除操作不要作为关键路径，影响核心流程。</li><li>方案3、方案4均适用于对延时要求比较高的业务，其区别为前者是推模式，后者是拉模式，而后者具有更强的可靠性，且无时序性问题。既然都愿意花功夫做处理消息的逻辑，不如一步到位，用方案4！</li></ol><h2 id="分布式锁" tabindex="-1"><a class="header-anchor" href="#分布式锁" aria-hidden="true">#</a> 分布式锁</h2><h3 id="分布式锁基础" tabindex="-1"><a class="header-anchor" href="#分布式锁基础" aria-hidden="true">#</a> 分布式锁基础</h3><blockquote><p>什么是分布式锁？</p></blockquote><ul><li>针对某项资源使用权限的管理，它通常用来控制共享资源 <ul><li>比如一个进程由多个线程竞争一个数据的使用权限，解决方式一就是加锁</li></ul></li><li>分布式锁，顾名思义就是分布式场景下的锁，比如多台不同机器上的进程竞争同一项资源</li></ul><blockquote><p>为什么需要分布式锁？</p></blockquote><ul><li>在分布式集群系统下，服务部署在多台服务器上，一个服务有一个JVM，以及一个锁监视器，synchronized只能保证单个JVM内部的线程实现互斥，所以synchronized只适合单体服务</li><li>nginx负载均衡，将请求发送到不同服务器上的服务中，每个服务都有一个JVM，他们的锁监视器不同，就可以获取锁，进而就会出现多台服务器上的进程都在操作共享资源</li><li>想要完善分布式模式下的共享资源的安全问题，就需要分布式锁，即多个服务依赖于同一个锁监视器</li></ul><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/1696685977503-841261e2-f235-469d-b5cf-b1469bf8fdf9.png" alt="image.png" tabindex="0" loading="lazy"><figcaption>image.png</figcaption></figure><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/1696685993935-11141151-b00d-4146-86d3-0e704b7bc74e.png" alt="image.png" tabindex="0" loading="lazy"><figcaption>image.png</figcaption></figure><h3 id="分布式锁特性" tabindex="-1"><a class="header-anchor" href="#分布式锁特性" aria-hidden="true">#</a> 分布式锁特性</h3><ul><li><strong>互斥性</strong>：只让一个竞争者持有锁；</li><li><strong>安全性</strong>：避免死锁情况发生。当一个竞争者在持有锁期间内，由于意外崩溃而导致未能主动解锁，其持有的锁也能够被正常释放，并保证后续其它竞争者也能加锁；</li><li><strong>对称性</strong>：同一个锁，加锁和解锁必须是同一个竞争者。不能把其他竞争者持有的锁给释放了，这又称为锁的可重入性。</li><li><strong>可靠性</strong>：需要有一定程度的异常处理能力、容灾能力</li></ul><h3 id="redis实现分布式锁" tabindex="-1"><a class="header-anchor" href="#redis实现分布式锁" aria-hidden="true">#</a> Redis实现分布式锁</h3><h4 id="互斥性" tabindex="-1"><a class="header-anchor" href="#互斥性" aria-hidden="true">#</a> 互斥性</h4><p>使用<code>SETNX</code>命令来<u>获得锁</u></p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>SET lock 1 NX
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><ul><li><code>SETNX</code>如果数据库中存在该key就设置失败并返回<code>(nio)</code>，如果不存在就设置成功并返回<code>ok</code></li></ul><p>通过删掉<code>lock</code>就可以实现<u>释放锁</u></p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>DEL lock
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><ul><li><code>DEL</code>命令删除键，返回的是删除的键数目，成功为1，失败为0</li></ul><h4 id="安全性" tabindex="-1"><a class="header-anchor" href="#安全性" aria-hidden="true">#</a> 安全性</h4><p>给<u>锁设置过期时间</u>就可以实现安全性</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>SET lock 1 NX EX &lt;TTL&gt;
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><ul><li>就算获得锁的业务线程崩溃了，没有释放锁，到过期时间锁还是能够自动释放</li><li>互斥性和安全性想要同时实现，就需要保证拿锁和设置过期时间是同时进行的 <ul><li>通过一条命令来完成拿锁和设置过期时间（一般是这个）</li><li>通过LUA脚本保证命令的原子性</li></ul></li></ul><h4 id="对称性" tabindex="-1"><a class="header-anchor" href="#对称性" aria-hidden="true">#</a> 对称性</h4><blockquote><p>误删</p></blockquote><ol><li>拿到锁的线程1因为种种原因（卡顿，阻塞，业务执行时间过久），在过期时间到达之后还没完成业务逻辑，锁被释放了</li><li>这时其他线程，线程2来尝试获得锁，就拿到了这把锁</li><li>线程2在持有锁执行过程中，线程1完成了业务逻辑（网络恢复，业务执行完毕），执行释放锁</li><li>此时就会把本应该属于线程2的锁进行删除</li></ol><blockquote><p>如何解决</p></blockquote><ul><li><p><u>线程只释放属于自己的锁</u>，给锁加上<code>owner</code></p><ul><li>每个线程释放锁的时候，去判断一下当前这把锁是否属于自己，如果不属于自己，则不进行锁的删除</li></ul></li><li><p>锁的key是相同的，应该通过value来判断这个锁是否属于自己</p><ul><li><p>在获取锁设置value的时候，可以初始化一个uuid，拼接上线程id，将其设置为value，确保value的唯一性</p></li><li><p>为什么不直接用线程id？</p><ul><li>因为每个JVM是通过维护一个递增的数字来确定线程id的，所以不同的JVM维护的递增数字是有可能相同的</li></ul></li></ul></li><li><p>要注意，<u>判断锁是否属于自己</u>和<u>释放锁</u>，这是两步操作，中间有可能会因为垃圾回收或其他原因发生阻塞，有可能判断的时候锁还是自己的，然后发生阻塞，自己的锁过期了，别人又抢到锁了，等阻塞结束删除锁的时候又误删了</p><ul><li>用<code>LUA</code>脚本可以保证判断锁和释放锁两步操作的原子性，杜绝上面这种情况</li></ul></li></ul><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/1696687507594-dd4bc8b0-cb44-4c6c-aba3-f26eec9912ae.png" alt="image.png" tabindex="0" loading="lazy"><figcaption>image.png</figcaption></figure><blockquote><p>如何正确设置超时时间</p></blockquote><p>一般需要在测试环境经过多轮压测，计算出平均执行时间</p><p>锁的超时时间应该设为平均执行时间的3-5倍</p><ul><li><p>给网络IO，JVM FullGC等留有缓冲时间</p></li><li><p>锁的超时时间也不能设置太大，一旦发生宕机，则该分布式锁的服务全部节点不可用</p></li></ul><blockquote><p>守护线程</p></blockquote><p>可以让获得锁的线程开启一个守护线程（看门狗），用来给快要过期的锁续航</p><p>加锁的时候设置一个过期时间，同时客户端开启一个守护线程，定时检测这个锁的失效时间</p><p>如果快要过期，业务逻辑还没实现，自动对这个锁进行续期，重设过期时间</p><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/86162FB12C06E7F044E70F366373AE2A.jpg" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><ol><li>通过 <code>SET lock_resource_name random_value NX PX expire_time</code>，同时启动守护线程为快要过期但还没执行完的客户端的锁续命;</li><li>客户端执行业务逻辑操作共享资源；</li><li>通过 <code>Lua</code> 脚本释放锁，先 get 判断锁是否是自己加的，再执行 <code>DEL</code>。</li></ol><h4 id="可靠性" tabindex="-1"><a class="header-anchor" href="#可靠性" aria-hidden="true">#</a> 可靠性</h4><blockquote><p>如果Redis挂掉了，锁就无法获取了，那么可靠性也就无法保证了</p></blockquote><p>一般来说有两种解决方法</p><ul><li><p>主从容灾</p><ul><li>使用Redis集群的主从模式，配合哨兵，防止单点Redis宕机导致数据丢失</li></ul></li><li><p><strong>多机部署</strong></p><ul><li>如果对一致性高，可以尝试多机部署，比如Redis的<strong>RedLock</strong></li><li>多个机器（通常为奇数个），达到一半以上同意加锁才算加锁成功 <ul><li>一台机器可以是一个单Redis节点，也可以是一个集群（一套主从跟哨兵）</li></ul></li><li>这样的可靠性会像ETCD靠近</li></ul><blockquote><p>ETCD与Redis有类似的功能，都可以用于实现分布式锁。它们的区别在于底层实现和特性。ETCD是一个基于Raft一致性算法的分布式键值存储系统，提供了高可用、强一致性和持久性的数据存储。</p></blockquote></li></ul><h5 id="多机部署流程-redlock" tabindex="-1"><a class="header-anchor" href="#多机部署流程-redlock" aria-hidden="true">#</a> 多机部署流程(RedLock)</h5><p>现在假设有5个Redis主节点，基本保证它们不会同时宕掉，获取锁和释放锁的过程中，客户端会执行以下操作：</p><ol><li>向5个Redis申请加锁，也就是向5个Redis发送set nx ex命令；</li><li>只要超过一半，也就是3个Redis返回成功，那么就是获取到了锁。如果超过一半失败，需要向每个Redis发送解锁命令，避免后面再次获取锁的时候，因为上一次获取锁失败时，申请成功的小于1/2的主节点的锁造成影响；</li></ol><blockquote><p>这样就可以避免主从模式下从机没有同步到锁的信息而让多个线程获取到同把锁的问题，因为红锁要成功拿到锁，得向多个实例发起请求，不会因为一个实例没有记录到锁信息就导致多个线程获取到同一把锁</p></blockquote><ol start="3"><li>由于向5个Redis发送请求，会有一定时耗，所以锁剩余持有时间，需要减去请求时间。这个可以作为判断依据，如果剩余时间已经为0，那么也是获取锁失败； <ul><li>也就是说，向5个Redis发送请求后，如果又1/2的主节点申请成功，这时候还不能判断获取锁成功，还需要判断锁超时释放时间是否长于向5个Redis申请锁的时间，才认为申请成功</li><li>避免因为申请过程中因为网络问题，导致在最先设置锁的节点，锁都超时释放了，别的主节点才申请成功，导致的实际设置锁的节点少于1/2的情况</li></ul></li><li>使用完成之后，向5个Redis发送解锁请求。</li></ol><h5 id="多机部署好处" tabindex="-1"><a class="header-anchor" href="#多机部署好处" aria-hidden="true">#</a> 多机部署好处</h5><ul><li>集群模式本身可靠性高 <ul><li>集群的所有手段，这种多机模式都可以使用，比如为每个节点配置哨兵模式，由于加锁是一半以上同意就成功，那么如果单个节点进行了主从切换，单个节点数据的丢失，就不会让锁失效了。这样增强了可靠性。</li></ul></li><li>过半实例申请锁成功才可以获取锁，避免主从模式下主从同步遗失锁信息的问题</li></ul><h5 id="可靠性深究" tabindex="-1"><a class="header-anchor" href="#可靠性深究" aria-hidden="true">#</a> 可靠性深究</h5><p>分布式系统的三大困境（NPC）</p><p><strong>N：Network Delay(网络延迟)</strong></p><ul><li>当分布式锁获得返回包的时间过长，此时可能虽然加锁成功，但是已经时过境迁，锁可能很快过期。</li><li>RedLock有相对应的措施，也就是前面所说的锁剩余持有时间，需要减去请求时间，可以一定程度解决网络延迟的问题。</li></ul><p><strong>P：Process Pause(进程暂停)</strong></p><blockquote><p>GC是Garbage Collection（垃圾回收）的缩写，是指自动内存管理机制，在程序运行时，自动寻找不再使用的对象（垃圾），并释放它们占有的内存空间，使这些内存可以被重新利用。</p></blockquote><p>比如发生GC，获取锁之后GC了，处于GC执行中，然后锁超时。</p><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/1696772397914-6520a857-e170-469f-b490-765951e9c507.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>其他锁获取，这种情况几乎无解。这时候GC回来了，那么两个进程就获取到了同一个分布式锁。</p><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/1696772398058-28169701-eadf-44e1-b834-ac0e84cdd36a.png" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>其实就是误删，保证对称性的问题就可以解决这个问题了</p><p><strong>C：Clock Drift(时钟漂移)</strong></p><p>如果竞争者A，获得了RedLock，在5台分布式机器上都加上锁。为了方便分析，我们直接假设5台机器都发生了时钟漂移，锁瞬间过期了。这时候竞争者B拿到了锁，此时A和B拿到了相同的执行权限。</p><p>根据上述的分析，可以看出，RedLock也不能扛住NPC的挑战，因此，单单从分布式锁本身出发，完全可靠是不可能的。要实现一个相对可靠的分布式锁机制，还是需要和业务的配合，业务本身要幂等可重入，这样的设计可以省却很多麻烦。</p><h4 id="redission" tabindex="-1"><a class="header-anchor" href="#redission" aria-hidden="true">#</a> Redission</h4><p>Redisson是一个在Redis的基础上实现的Java驻内存数据网格（In-Memory Data Grid）。它不仅提供了一系列的分布式的Java常用对象，还提供了许多分布式服务，其中就包含了各种分布式锁的实现。同时还实现了许多其他的锁。</p><blockquote><p>基于SETNX实现的分布式锁存在问题</p></blockquote><ul><li><p><strong>重入问题</strong>：<u>重入是指获得锁的线程可以再次进入到相同的锁的代码块中</u>，可重入锁的意义在于防止死锁</p><ul><li>比如HashTable这样的代码中，他的方法都是使用synchronized修饰的，假如他在一个方法内，调用另一个方法，那么此时如果是不可重入的，不就死锁了吗？所以可重入锁他的主要意义是防止死锁，我们的synchronized和Lock锁都是可重入的。</li></ul><ul><li>同一个线程无法多次获取同一把锁，比如说，一个线程调用了方法A，方法A又调用了方法B，在方法A中要先获取锁，然后执行业务调B，而B中又要获取同一把锁。如果锁是不可重入的，在方法A中获取了锁，在方法B中，又想要获取这把锁，但无法获取，此时就会等待锁的释放，但是方法A占用锁，还没有执行完，还在调用B，此时就会出现死锁的情况。</li></ul></li><li><p><strong>不可重试</strong>：是指目前的分布式只能尝试一次</p><ul><li>合理的情况是：<u>当线程在获得锁失败后，他应该能再次尝试获得锁。</u></li></ul></li><li><p>**超时释放：**我们在加锁时增加了过期时间，这样的我们可以防止死锁</p><ul><li>但是如果卡顿的时间超长，虽然我们采用了lua表达式防止删锁的时候误删别人的锁，但是毕竟存在超时释放的情况，仍然存在安全隐患</li></ul></li><li><p><strong>主从一致性：</strong> 如果Redis提供了主从集群，当我们向集群写数据时，主机需要异步的将数据同步给从机，而万一在同步过去之前，主机宕机了，从节点就没有锁信息，可能会出现多个线程共用一把锁的情况。</p><ul><li>不过主从同步耗时很短，在毫秒级别，所以出现的概率其实比较低。</li></ul></li></ul><h5 id="redisson可重入锁" tabindex="-1"><a class="header-anchor" href="#redisson可重入锁" aria-hidden="true">#</a> Redisson可重入锁</h5><blockquote><p>Redisson可重入锁如何使用</p></blockquote><ol><li>引入依赖</li></ol><div class="language-xml line-numbers-mode" data-ext="xml"><pre class="language-xml"><code><span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>dependency</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>groupId</span><span class="token punctuation">&gt;</span></span>org.redisson<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>groupId</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>artifactId</span><span class="token punctuation">&gt;</span></span>redisson<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>artifactId</span><span class="token punctuation">&gt;</span></span>
  <span class="token tag"><span class="token tag"><span class="token punctuation">&lt;</span>version</span><span class="token punctuation">&gt;</span></span>3.13.6<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>version</span><span class="token punctuation">&gt;</span></span>
<span class="token tag"><span class="token tag"><span class="token punctuation">&lt;/</span>dependency</span><span class="token punctuation">&gt;</span></span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ol start="2"><li>配置Redisson客户端</li></ol><div class="language-java line-numbers-mode" data-ext="java"><pre class="language-java"><code><span class="token annotation punctuation">@Configuration</span>
<span class="token keyword">public</span> <span class="token keyword">class</span> <span class="token class-name">RedissonConfig</span> <span class="token punctuation">{</span>
    <span class="token annotation punctuation">@Bean</span>
    <span class="token keyword">public</span> <span class="token class-name">RedissonClient</span> <span class="token function">redissonClient</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">{</span>
        <span class="token comment">// 配置</span>
        <span class="token class-name">Config</span> config <span class="token operator">=</span> <span class="token keyword">new</span> <span class="token class-name">Config</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        config<span class="token punctuation">.</span><span class="token function">useSingleServer</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token function">setAddress</span><span class="token punctuation">(</span><span class="token string">&quot;redis://localhost:6379&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token comment">// 创建RedissonClient对象</span>
        <span class="token keyword">return</span> <span class="token class-name">Redisson</span><span class="token punctuation">.</span><span class="token function">create</span><span class="token punctuation">(</span>config<span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ol start="3"><li>使用Redisson锁</li></ol><div class="language-java line-numbers-mode" data-ext="java"><pre class="language-java"><code><span class="token annotation punctuation">@Resource</span>
<span class="token keyword">private</span> <span class="token class-name">RedissionClient</span> redissonClient<span class="token punctuation">;</span>

<span class="token annotation punctuation">@Test</span>
<span class="token keyword">public</span> <span class="token keyword">void</span> <span class="token function">testRedisson</span><span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token keyword">throws</span> <span class="token class-name">Exception</span><span class="token punctuation">{</span>
    <span class="token comment">// 获取锁(可重入)，指定锁的名称：如&#39;lock:order:&#39;</span>
    <span class="token class-name">RLock</span> lock <span class="token operator">=</span> redissonClient<span class="token punctuation">.</span><span class="token function">getLock</span><span class="token punctuation">(</span><span class="token string">&quot;anyLock&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">// 尝试获取锁，参数分别是：获取锁的最大等待时间(期间会重试)，锁自动释放时间，时间单位</span>
    <span class="token comment">// 如果没有传递参数，默认最大等待时间为-1，即不等待，默认超时释放时间为30s</span>
	<span class="token keyword">boolean</span> isLock <span class="token operator">=</span> lock<span class="token punctuation">.</span><span class="token function">tryLock</span><span class="token punctuation">(</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">10</span><span class="token punctuation">,</span><span class="token class-name">TimeUnit</span><span class="token punctuation">.</span><span class="token constant">SECONDS</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
    <span class="token comment">//判断获取锁成功</span>
    <span class="token keyword">if</span><span class="token punctuation">(</span>isLock<span class="token punctuation">)</span><span class="token punctuation">{</span>
        <span class="token keyword">try</span><span class="token punctuation">{</span>
            <span class="token class-name">System</span><span class="token punctuation">.</span>out<span class="token punctuation">.</span><span class="token function">println</span><span class="token punctuation">(</span><span class="token string">&quot;执行业务&quot;</span><span class="token punctuation">)</span><span class="token punctuation">;</span>          
        <span class="token punctuation">}</span><span class="token keyword">finally</span><span class="token punctuation">{</span>
            <span class="token comment">//释放锁</span>
            lock<span class="token punctuation">.</span><span class="token function">unlock</span><span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">;</span>
        <span class="token punctuation">}</span>
    <span class="token punctuation">}</span>
<span class="token punctuation">}</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><blockquote><p>Redisson可重入锁是如何实现的</p></blockquote><ul><li>因为可重入锁需要记录获取锁的次数，所以在设置锁的时候不再使用String的结构，使用Hash结构</li></ul><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20231122124917480.png" alt="image-20231122124917480" tabindex="0" loading="lazy"><figcaption>image-20231122124917480</figcaption></figure><ul><li>获取锁的时候，相比起之前的操作，多了需要判断锁的持有者是不是自己，如果是自己，则设置重入次数加一</li><li>释放锁的时候，除了要判断锁的持有者是自己外，需要先将重入次数-1，删除锁之前，要先判断重入次数是否为0，是的话才删除锁 <ul><li>这样才可以确保是在最外层持有锁的服务中将锁释放，如果在内层把锁直接删了释放，外层需要锁权限的代码还没执行完，就会出现线程安全问题</li></ul></li></ul><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20231122124937444.png" alt="image-20231122124937444" tabindex="0" loading="lazy"><figcaption>image-20231122124937444</figcaption></figure><h5 id="redisson锁重试机制" tabindex="-1"><a class="header-anchor" href="#redisson锁重试机制" aria-hidden="true">#</a> Redisson锁重试机制</h5><p><strong>锁重试实现</strong></p><p><code>tryLock()</code>方法会传入一个等待时间和一个过期时间</p><ul><li>等待时间是获取锁重试的时间</li><li>过期时间是获取到锁之后锁的过期时间 <ul><li>如果过期时间不设置，默认会开启看门狗机制</li></ul></li></ul><p><strong>巧妙之处</strong></p><ul><li>采用了消息订阅锁释放的信息来尝试获取的，等收到了锁释放的信息才再次尝试获取锁，而不是采取无休止的固定时间按的自旋式的等待（这种方式对CPU是一种浪费）</li></ul><p><strong>简单流程</strong></p><ol><li>尝试获取锁失败</li><li>检查剩余等待时间是否大于0</li><li>是则等待释放锁的信号</li><li>判断等待时间是否超时，未超时且没有获取锁，则再次尝试获取锁</li><li>如果成功则获取锁，如果失败则回到步骤二</li></ol><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/1696840311684-e57e75c0-9a4c-4dfa-b838-dad6798abc19-17006335304037.png" alt="image.png" tabindex="0" loading="lazy"><figcaption>image.png</figcaption></figure><h5 id="redisson的watchdog机制" tabindex="-1"><a class="header-anchor" href="#redisson的watchdog机制" aria-hidden="true">#</a> Redisson的watchDog机制</h5><blockquote><p>上面提到的守护线程，给业务续期</p></blockquote><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/E3D9A8FBA6D11E065BFECC2721AE7A59.jpg" alt="img" tabindex="0" loading="lazy"><figcaption>img</figcaption></figure><p>默认情况下，看门狗的续期时间是 30s，也可以通过修改 <code>Config.lockWatchdogTimeout</code> 来另行指定。</p><p>另外 <code>Redisson</code> 还提供了可以指定 <code>leaseTime</code> 参数的加锁方法来指定加锁的时间。</p><p>超过这个时间后锁便自动解开了，不会延长锁的有效期。</p><ul><li>watchDog <strong>只有在未显示指定加锁超时时间（leaseTime）时才会生效</strong>。</li><li>lockWatchdogTimeout 设定的时间不要太小 ，比如设置的是 100 毫秒，由于网络直接导致加锁完后，watchdog 去延期时，这个 key 在 redis 中已经被删除了</li></ul><h4 id="redis实现分布式锁优缺点" tabindex="-1"><a class="header-anchor" href="#redis实现分布式锁优缺点" aria-hidden="true">#</a> Redis实现分布式锁优缺点</h4><h5 id="优点" tabindex="-1"><a class="header-anchor" href="#优点" aria-hidden="true">#</a> 优点</h5><ol><li>性能高效（这是选择缓存实现分布式锁最核心的出发点）。</li><li>实现方便。很多研发工程师选择使用 Redis 来实现分布式锁，很大成分上是因为 Redis 提供了 setnx 方法，实现分布式锁很方便。</li><li>避免单点故障（因为 Redis 是跨集群部署的，自然就避免了单点故障）。</li></ol><h5 id="缺点" tabindex="-1"><a class="header-anchor" href="#缺点" aria-hidden="true">#</a> 缺点</h5><ol><li>不合理设置超时时间</li><li>Redis 集群的数据同步机制</li><li>都会导致分布式锁的不可靠性，即多个线程具有锁权限</li></ol><h3 id="其他技术实现分布式锁" tabindex="-1"><a class="header-anchor" href="#其他技术实现分布式锁" aria-hidden="true">#</a> 其他技术实现分布式锁</h3><h4 id="分布式锁的实现思路" tabindex="-1"><a class="header-anchor" href="#分布式锁的实现思路" aria-hidden="true">#</a> 分布式锁的实现思路</h4><ul><li><p><strong>互斥、可重入</strong></p><p>- 创建锁必须是唯一的，表现形式为向数据存储服务器或容器插入一个唯一的 key，一旦有一个线程插入这个 key，其他线程就不能再插入了。</p><ul><li><p>保证 key 唯一性的最简单的方式是使用 UUID。</p></li><li><p>存储锁的重入次数，以及分布式环境下唯一的线程标识。举例来说，可以使用 json 存储结构化数据，为了保证唯一，可以考虑将 mac 地址（IP 地址、机器 ID）、Jvm 进程 ID（应用 ID、服务 ID）、线程 ID 拼接起来作为唯一标识。</p><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>{&quot;count&quot;:1,&quot;expireAt&quot;:147506817232,&quot;jvmPid&quot;:22224,&quot;mac&quot;:&quot;28-D2-44-0E-0D-9A&quot;,&quot;threadId&quot;:14}
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div></li></ul></li><li><p><strong>避免死锁</strong> - 数据库分布式锁和缓存分布式锁（Redis）的思路都是引入超时机制，即成功申请锁后，超过一定时间，锁失效（删除 key），原因在于它们无法感知申请锁的客户端节点状态。而 ZooKeeper 由于其 znode 以目录、文件形式组织，天然就存在物理空间隔离，只要 znode 存在，即表示客户端节点还在工作，所以不存在这种问题。</p></li><li><p><strong>容错</strong> - 只要大部分 Redis 节点可用，客户端就能正常加锁。</p></li><li><p><strong>自旋重试</strong> - 获取不到锁时，不要直接返回失败，而是支持一定的周期自旋重试，设置一个总的超时时间，当过了超时时间以后还没有获取到锁则返回失败。</p></li></ul><h4 id="数据库实现分布式锁" tabindex="-1"><a class="header-anchor" href="#数据库实现分布式锁" aria-hidden="true">#</a> 数据库实现分布式锁</h4><h5 id="原理" tabindex="-1"><a class="header-anchor" href="#原理" aria-hidden="true">#</a> 原理</h5><p>（1）创建表</p><div class="language-sql line-numbers-mode" data-ext="sql"><pre class="language-sql"><code><span class="token keyword">CREATE</span> <span class="token keyword">TABLE</span> <span class="token identifier"><span class="token punctuation">\`</span>methodLock<span class="token punctuation">\`</span></span> <span class="token punctuation">(</span>
  <span class="token identifier"><span class="token punctuation">\`</span>id<span class="token punctuation">\`</span></span> <span class="token keyword">int</span><span class="token punctuation">(</span><span class="token number">11</span><span class="token punctuation">)</span> <span class="token operator">NOT</span> <span class="token boolean">NULL</span> <span class="token keyword">AUTO_INCREMENT</span> <span class="token keyword">COMMENT</span> <span class="token string">&#39;主键&#39;</span><span class="token punctuation">,</span>
  <span class="token identifier"><span class="token punctuation">\`</span>method_name<span class="token punctuation">\`</span></span> <span class="token keyword">varchar</span><span class="token punctuation">(</span><span class="token number">64</span><span class="token punctuation">)</span> <span class="token operator">NOT</span> <span class="token boolean">NULL</span> <span class="token keyword">DEFAULT</span> <span class="token string">&#39;&#39;</span> <span class="token keyword">COMMENT</span> <span class="token string">&#39;锁定的方法名&#39;</span><span class="token punctuation">,</span>
  <span class="token identifier"><span class="token punctuation">\`</span>desc<span class="token punctuation">\`</span></span> <span class="token keyword">varchar</span><span class="token punctuation">(</span><span class="token number">1024</span><span class="token punctuation">)</span> <span class="token operator">NOT</span> <span class="token boolean">NULL</span> <span class="token keyword">DEFAULT</span> <span class="token string">&#39;备注信息&#39;</span><span class="token punctuation">,</span>
  <span class="token identifier"><span class="token punctuation">\`</span>update_time<span class="token punctuation">\`</span></span> <span class="token keyword">timestamp</span> <span class="token operator">NOT</span> <span class="token boolean">NULL</span> <span class="token keyword">DEFAULT</span> <span class="token keyword">CURRENT_TIMESTAMP</span> <span class="token keyword">ON</span> <span class="token keyword">UPDATE</span> <span class="token keyword">CURRENT_TIMESTAMP</span> <span class="token keyword">COMMENT</span> <span class="token string">&#39;保存数据时间，自动生成&#39;</span><span class="token punctuation">,</span>
  <span class="token keyword">PRIMARY</span> <span class="token keyword">KEY</span> <span class="token punctuation">(</span><span class="token identifier"><span class="token punctuation">\`</span>id<span class="token punctuation">\`</span></span><span class="token punctuation">)</span><span class="token punctuation">,</span>
  <span class="token keyword">UNIQUE</span> <span class="token keyword">KEY</span> <span class="token identifier"><span class="token punctuation">\`</span>uidx_method_name<span class="token punctuation">\`</span></span> <span class="token punctuation">(</span><span class="token identifier"><span class="token punctuation">\`</span>method_name <span class="token punctuation">\`</span></span><span class="token punctuation">)</span> <span class="token keyword">USING</span> <span class="token keyword">BTREE</span>
<span class="token punctuation">)</span> <span class="token keyword">ENGINE</span><span class="token operator">=</span><span class="token keyword">InnoDB</span> <span class="token keyword">DEFAULT</span> <span class="token keyword">CHARSET</span><span class="token operator">=</span>utf8 <span class="token keyword">COMMENT</span><span class="token operator">=</span><span class="token string">&#39;锁定中的方法&#39;</span><span class="token punctuation">;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><p>（2）获取锁</p><p>想要锁住某个方法时，执行以下 SQL：</p><div class="language-sql line-numbers-mode" data-ext="sql"><pre class="language-sql"><code><span class="token keyword">insert</span> <span class="token keyword">into</span> methodLock<span class="token punctuation">(</span>method_name<span class="token punctuation">,</span><span class="token keyword">desc</span><span class="token punctuation">)</span> <span class="token keyword">values</span> <span class="token punctuation">(</span>‘method_name’<span class="token punctuation">,</span>‘<span class="token keyword">desc</span>’<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><p>因为我们对 <code>method_name</code> 做了唯一性约束，这里如果有多个请求同时提交到数据库的话，数据库会保证只有一个操作可以成功，那么我们就可以认为操作成功的那个线程获得了该方法的锁，可以执行方法体内容。</p><p>成功插入则获取锁。</p><p>（3）释放锁</p><p>当方法执行完毕之后，想要释放锁的话，需要执行以下 Sql:</p><div class="language-sql line-numbers-mode" data-ext="sql"><pre class="language-sql"><code><span class="token keyword">delete</span> <span class="token keyword">from</span> methodLock <span class="token keyword">where</span> method_name <span class="token operator">=</span><span class="token string">&#39;method_name&#39;</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h5 id="存在问题" tabindex="-1"><a class="header-anchor" href="#存在问题" aria-hidden="true">#</a> 存在问题</h5><ul><li>这把锁强依赖数据库的可用性。如果数据库是一个单点，一旦数据库挂掉，会导致业务系统不可用。</li><li>这把锁没有失效时间，一旦解锁操作失败，就会导致锁记录一直在数据库中，其他线程无法再获得到锁。</li><li>这把锁只能是非阻塞的，因为数据的 insert 操作，一旦插入失败就会直接报错。没有获得锁的线程并不会进入排队队列，要想再次获得锁就要再次触发获得锁操作。</li><li>这把锁是非重入的，同一个线程在没有释放锁之前无法再次获得该锁。因为数据中数据已经存在了。</li></ul><p><strong>解决办法</strong></p><ul><li>单点问题可以用多数据库实例，同时塞 N 个表，N/2+1 个成功就任务锁定成功（红锁）</li><li>写一个定时任务，隔一段时间清除一次过期的数据。</li><li>写一个 while 循环，不断的重试插入，直到成功。</li><li>在数据库表中加个字段，记录当前获得锁的机器的主机信息和线程信息，那么下次再获取锁的时候先查询数据库，如果当前机器的主机信息和线程信息在数据库可以查到的话，直接把锁分配给他就可以了。</li></ul><h5 id="小结" tabindex="-1"><a class="header-anchor" href="#小结" aria-hidden="true">#</a> 小结</h5><ul><li>优点: 直接借助数据库，容易理解。</li><li>缺点: 会有各种各样的问题，在解决问题的过程中会使整个方案变得越来越复杂。操作数据库需要一定的开销，性能问题需要考虑。</li></ul><h4 id="zookeeper-分布式锁" tabindex="-1"><a class="header-anchor" href="#zookeeper-分布式锁" aria-hidden="true">#</a> ZooKeeper 分布式锁</h4><h5 id="原理-1" tabindex="-1"><a class="header-anchor" href="#原理-1" aria-hidden="true">#</a> 原理</h5><p>ZooKeeper 实现分布式锁基于 ZooKeeper 的两个特性：</p><ul><li><strong>顺序临时节点</strong><ul><li>ZooKeeper 的存储类似于 DNS 那样的具有层级的命名空间。ZooKeeper 节点类型可以分为持久节点（PERSISTENT ）、临时节点（EPHEMERAL），每个节点还能被标记为有序性（SEQUENTIAL），一旦节点被标记为有序性，那么整个节点就具有顺序自增的特点。</li></ul></li><li><strong>Watch 机制</strong><ul><li>ZooKeeper 允许用户在指定节点上注册一些 Watcher，并且在特定事件触发的时候，ZooKeeper 服务端会将事件通知给用户。</li></ul></li></ul><p>这也是 ZooKeeper 客户端 curator 的分布式锁实现。</p><ol><li>创建一个目录 mylock；</li><li>线程 A 想获取锁就在 mylock 目录下创建临时顺序节点；</li><li>获取 mylock 目录下所有的子节点，然后获取比自己小的兄弟节点，如果不存在，则说明当前线程顺序号最小，获得锁；</li><li>线程 B 获取所有节点，判断自己不是最小节点，设置监听比自己次小的节点；</li><li>线程 A 处理完，删除自己的节点，线程 B 监听到变更事件，判断自己是不是最小的节点，如果是则获得锁。</li></ol><h5 id="小结-1" tabindex="-1"><a class="header-anchor" href="#小结-1" aria-hidden="true">#</a> 小结</h5><p>ZooKeeper 版本的分布式锁问题相对比较来说少。</p><ul><li>锁的占用时间限制：redis 就有占用时间限制，而 ZooKeeper 则没有，最主要的原因是 redis 目前没有办法知道已经获取锁的客户端的状态，是已经挂了呢还是正在执行耗时较长的业务逻辑。而 ZooKeeper 通过临时节点就能清晰知道，如果临时节点存在说明还在执行业务逻辑，如果临时节点不存在说明已经执行完毕释放锁或者是挂了。由此看来 redis 如果能像 ZooKeeper 一样添加一些与客户端绑定的临时键，也是一大好事。</li><li>是否单点故障：redis 本身有很多中玩法，如客户端一致性 hash，服务器端 sentinel 方案或者 cluster 方案，很难做到一种分布式锁方式能应对所有这些方案。而 ZooKeeper 只有一种玩法，多台机器的节点数据是一致的，没有 redis 的那么多的麻烦因素要考虑。</li></ul><p>总体上来说 ZooKeeper 实现分布式锁更加的简单，可靠性更高。但 ZooKeeper 因为需要频繁的创建和删除节点，性能上不如 Redis 方式。</p><h4 id="分布式锁方案对比" tabindex="-1"><a class="header-anchor" href="#分布式锁方案对比" aria-hidden="true">#</a> 分布式锁方案对比</h4><p>性能：Redis最好，Zookeeper次之，数据库最差</p><p>实现方式和可靠性：Zookeeper实现方式简单，基于分布式集群，可以避免单点问题，具有较高的可靠性</p><blockquote><p>如何选择</p></blockquote><p>在对业务性能要求不是很高的场景中，建议使用Zookeeper实现的分布式锁</p><h2 id="秒杀" tabindex="-1"><a class="header-anchor" href="#秒杀" aria-hidden="true">#</a> 秒杀</h2><h3 id="秒杀基础" tabindex="-1"><a class="header-anchor" href="#秒杀基础" aria-hidden="true">#</a> 秒杀基础</h3><blockquote><p>什么是秒杀</p></blockquote><p>秒杀通常指因为某种活动瞬时产生巨大流量的场景，比如双十一0点抢10000个苹果手机，这种活动一般会吸引几十万甚至上百万的人参与，大家都盯着0点，等0点一到就是海量的请求</p><blockquote><p>秒杀活动有什么问题</p></blockquote><p><strong>海量请求</strong></p><ul><li>秒杀活动一开始，瞬间就会有海量流量涌入，热门的商品甚至会有几百万人来抢</li><li>这样规模的流量下来，服务可能就挂了，活动也就GG了</li></ul><p><strong>不能超卖</strong></p><ul><li>秒杀有时候就是赔本赚吆喝，价格可能比成本价还低，如果这个时候比原计划的数量卖多了，最后应不应该发货呢</li><li>发货会超预算亏损，不发货会被投诉</li></ul><p><strong>避免少卖</strong></p><ul><li>少卖比超卖好点，商家不存在经济上的亏损</li><li>但是要是被眼尖的消费者发现，免不了一场麻烦</li></ul><p><strong>筛选黄牛</strong></p><ul><li>黄牛可能开脚本，一次发很多请求来买，抢到之后再去转卖</li><li>做活动的目的是为了回馈客户，进而吸引用户，而不是让黄牛赚外快</li></ul><blockquote><p>如何解决这些问题</p></blockquote><p>秒杀活动的主要思路是**<u>削峰，限流，异步，补偿</u>**</p><h3 id="抗住海量请求" tabindex="-1"><a class="header-anchor" href="#抗住海量请求" aria-hidden="true">#</a> 抗住海量请求</h3><blockquote><p>秒杀的高并发场景下，所有请求一下打到数据库，会给数据库巨大的压力，所以可以使用Redis来承担压力</p></blockquote><h4 id="抢单购买分离" tabindex="-1"><a class="header-anchor" href="#抢单购买分离" aria-hidden="true">#</a> 抢单购买分离</h4><p>将抢单和购买解耦，抢单使用Redis来处理，还可以方便的进行限额，异步购买使用消息队列来处理</p><ol><li>将库存名额缓存到Redis，在Redis中还可以维护一个数据结构来存放抢到的用户，用以限额</li><li>用户发起下单请求，在Redis里面做校验，校验库存和限买个数 <ul><li>不能让MySQL出现在同步的流程中，把数据拿给Redis让Redis来干</li></ul></li><li>通过就发消息给消息队列，把用户下单时的订单信息一并打包发过去</li><li>订单信息进入消息队列就说明用户抢单成功</li><li>MySQL那边异步消费消息对用户的订单信息进行购买操作 <ul><li>由消息的消费者去完成扣减数据库中商品库存和生成用户订单的操作</li></ul></li></ol><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20231122235257038.png" alt="image-20231122235257038" tabindex="0" loading="lazy"><figcaption>image-20231122235257038</figcaption></figure><h4 id="多个redis分流" tabindex="-1"><a class="header-anchor" href="#多个redis分流" aria-hidden="true">#</a> 多个Redis分流</h4><ul><li><p>如果<u>请求量超过6w/s</u>，那么可以考虑<strong>使用多个Redis来分流，每个Redis拥有一定量的库存，使用Nginx负载均衡</strong>，将请求分摊到各个Redis实例上</p></li><li><ul><li>比如，预计由100w/s的流量，就可以将其以5w/s的流量分摊到20个Redis实例上，留1w/s的缓冲空间</li><li>实际上，6w是一个估计值，Redis承受10w/s的流量也是能够接受的，所以需要根据实际情况而定</li></ul></li></ul><blockquote><p>注意这并可以不用搭建Redis集群，搭建Redis集群会自动根据key来定位请求哪台Redis，这里使用Nginx负载均衡就行</p></blockquote><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/1698232862648-473b3ba5-741b-449a-a291-60074a4ec503.png" alt="image.png" tabindex="0" loading="lazy"><figcaption>image.png</figcaption></figure><h3 id="拒绝超卖" tabindex="-1"><a class="header-anchor" href="#拒绝超卖" aria-hidden="true">#</a> 拒绝超卖</h3><blockquote><p>什么是超卖</p></blockquote><p>库存只有100，高并发的场景下卖出了大于100</p><blockquote><p>为什么会超卖</p></blockquote><p>抢购场景核心就两个步骤</p><ol><li>判断库存名额是否充足</li><li>扣减库存名额，扣减成功就是抢到了</li></ol><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20231123002600367.png" alt="image-20231123002600367" tabindex="0" loading="lazy"><figcaption>image-20231123002600367</figcaption></figure><p>但是，如果第一步判断的时候还有库存，由于并发操作，实际调用扣减库存的时候可能已经没有库存了，这样就会造成超卖</p><h4 id="lua脚本" tabindex="-1"><a class="header-anchor" href="#lua脚本" aria-hidden="true">#</a> LUA脚本</h4><p>使用LUA脚本将两步操作原子化，合二为一，就不存在并发导致的超卖问题了</p><p>使用LUA脚本之后其他异常情况：</p><ul><li>正常业务错误：如库存用完，直接返回</li><li>访问Redis错误：直接返回给用户，让其重试</li><li>访问Redis超时：这种情况下，可能扣了可能没扣，就不让用户重试了，如果没扣就刚好，如果扣了就当少卖了</li></ul><h3 id="避免少卖" tabindex="-1"><a class="header-anchor" href="#避免少卖" aria-hidden="true">#</a> 避免少卖</h3><blockquote><p>什么情况下会出现少卖</p></blockquote><p>库存减少了，用户订单没有生成</p><ul><li>减少库存操作超时，但实际是成功的，因为超时并不会进入生成订单流程 <ul><li>小概率事件，一般可以进行<strong>补偿</strong></li><li>比如卖完之后发现少了，重新放进去</li></ul></li><li>在Redis操作成功，但是向Kafka发送信息失败，这种情况也会白白消耗Redis中的库存 <ul><li>一般都是这种情况，<strong>保证Redis库存和Kafka消耗的最终一致性</strong></li></ul></li></ul><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20231128203423149.png" alt="image-20231128203423149" tabindex="0" loading="lazy"><figcaption>image-20231128203423149</figcaption></figure><blockquote><p>如何保证Redis库存和Kafka消耗的最终一致性</p></blockquote><ul><li><p>第一种，也最简单的方式，在投递Kafka失败的情况下，增加<strong>渐进式重试</strong></p><ul><li>渐进式重试：<code>sleep(1s)</code>后重试，若失败，<code>sleep(3s)</code>后重试，若失败，<code>sleep(6s)</code>后重试......</li><li>渐进式这样一点一点增多，一般有个最大的时间，比如后面一小时重试一次（就像密码输错了会锁机，错误次数增加，锁机时间会越来越长）。</li><li>和固定时间进行重试相比，区别在于渐进式重试越来越懒惰，所以可能发现得比较慢，但是消耗也少。固定重试就是发现比较快(当然一开始也可以选择很久重试一次) <ul><li>同时，一般失败的话后面其实大概率也是失败，这种拉长时间的作法还是蛮多的。</li><li>比如说微信支付回调里的通知频率为<code>15s/15s/30s/3m/10m/20m/30m/30m/30m/60m/3h/3h/3h/6h/6h</code>- 总计 24h4m</li></ul></li></ul></li><li><p>第二种，更安全一点，就是在第一种的基础上，<strong>将这条消息记录在磁盘上慢慢重试</strong>(一般选这个)</p><ul><li>针对少卖这种极端场景可接受的问题，毕竟是异常情况的小概率事件，真出问题了大不了人工介入（而且感觉记录在磁盘中，维护的人员也可以看到磁盘中的记录来发现问题）</li></ul></li><li><p>第三种，写磁盘之前就可能失败，可以考虑走<strong>WAL</strong>路线，但是这样做下去说不定就做成MySQL的undo log，redo log这种WAL技术了，会相当复杂，没有必要</p></li></ul><h3 id="限量和限速" tabindex="-1"><a class="header-anchor" href="#限量和限速" aria-hidden="true">#</a> 限量和限速</h3><h4 id="限速" tabindex="-1"><a class="header-anchor" href="#限速" aria-hidden="true">#</a> 限速</h4><blockquote><p>黄牛一般会使用脚本来抢单，点击速度会比一般人快</p></blockquote><p>如果某个用户请求接口次数过于频繁，就要对其进行限制</p><ul><li>针对IP：容易误伤，使用同一个网络的用户，可能都是一个IP出口</li><li>使用验证码：验证码符合91原则，90%的时间在输验证码，10%时间用来抢</li></ul><h4 id="限量" tabindex="-1"><a class="header-anchor" href="#限量" aria-hidden="true">#</a> 限量</h4><p>限量和库存扣减存在同样的问题</p><ul><li>同一个用户，使用多个线程同时抢，就会出现一个用户多个订单的情况</li><li>如果是Redis分片集群要根据用户来分key（Hash Tag），要确保一个用户的数据落在一个节点上，否则需要查多个节点来聚合，会影响性能</li><li>想保证限量，就需要保证查询数据到修改数据之间没有别的线程来操作数据</li></ul><blockquote><p><strong>如何确保原子性</strong></p></blockquote><h5 id="lua脚本-1" tabindex="-1"><a class="header-anchor" href="#lua脚本-1" aria-hidden="true">#</a> LUA脚本</h5><p>如果库存信息记录在Redis中，使用LUA脚本判断用户是否具有购买资格不应该只以库存量为依据，还应该检查购买记录</p><ol><li>判断库存是否充足</li><li>判断用户是否超额</li><li>扣减库存</li><li>记录用户购买记录</li></ol><h5 id="悲观锁sychronized" tabindex="-1"><a class="header-anchor" href="#悲观锁sychronized" aria-hidden="true">#</a> 悲观锁sychronized</h5><p>在单体系统下，可以使用sychronized加锁来确保原子性</p><blockquote><p>为什么使用悲观锁而不是乐观锁？</p></blockquote><ul><li>乐观锁适合数据修改时使用，比如修改库存，因为修改就会存在版本</li><li>乐观锁并不适用与查询订单数量的场景，所以要使用悲观锁</li><li>从查询是否存在订单，到下单，都需要使用锁，确保只有一个线程在执行这个操作</li></ul><blockquote><p>使用sychronized的时候，如果使用用户id作为锁，直接使用<code>userId.toString()</code>拿到的对象是不同的对象，此时需要使用<code>intern()</code>方法来确保获取同一个引用</p></blockquote><ul><li>将一个对象的字符串表示进行内部化(<code>intern</code>)，也就是将其添加到Java虚拟机的字符串常量池中，并返回该字符串在常量池中的引用</li><li>在Java中，字符串是不可变的对象，因此如果有多个字符串具有相同的值，那么它们可以共享同一个实例，以节省内存和提高效率。这就是字符串常量池的作用。</li><li>调用intern()方法时，如果字符串常量池中已经存在一个与该字符串值相等的字符串，则返回常量池中的引用；否则将该字符串加入常量池中，并返回该字符串在常量池中的引用。</li></ul><h5 id="分布式锁-1" tabindex="-1"><a class="header-anchor" href="#分布式锁-1" aria-hidden="true">#</a> 分布式锁</h5><p>在分布式系统，由于每个JVM都有一个锁监视器，sychronized无法保证只有单个线程获取到锁，所以需要使用分布式锁</p><p>实现分布式锁需要考虑误删、原子性等问题</p><h3 id="redis的作用" tabindex="-1"><a class="header-anchor" href="#redis的作用" aria-hidden="true">#</a> Redis的作用</h3><p>Redis在秒杀中扮演扣减库存的角色，这个主要是因为Redis比关系型存储高很多性能。</p><p>除了扣除库存，Reds还可以用做队列</p><ul><li>虽然不如传统消息队列可靠，但是胜利在轻量级</li></ul><h2 id="事务" tabindex="-1"><a class="header-anchor" href="#事务" aria-hidden="true">#</a> 事务</h2><h3 id="事务基础" tabindex="-1"><a class="header-anchor" href="#事务基础" aria-hidden="true">#</a> 事务基础</h3><blockquote><p>什么是事务</p></blockquote><p>事务就是多个操作被看作一个整体</p><p>事务通常具有原子性</p><h3 id="multi事务" tabindex="-1"><a class="header-anchor" href="#multi事务" aria-hidden="true">#</a> Multi事务</h3><p>Redis原生的Multi命令可以用于开启事务</p><p>原生事务是由MULTI，EXEC，DISCARD和WATCH四个命令组成的</p><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20231128214516830.png" alt="image-20231128214516830" tabindex="0" loading="lazy"><figcaption>image-20231128214516830</figcaption></figure><ol><li>watch：监督某个或多个key是否发生变化，如果发生变化，事务不执行</li><li>multi：开启事务</li><li>discard：取消事务 <ul><li>输入redis的读写命令后，又不想要这个事务了，就是用该命令结束事务，就当无事发生过</li></ul></li><li>exec：提交事务</li></ol><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code><span class="token comment">#开启事务</span>
<span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>&gt;</span> MULTI
OK
<span class="token comment">#将a:stock减1，</span>
<span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>&gt;</span> DECR a:stock
QUEUED
<span class="token comment">#将b:stock减1</span>
<span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>&gt;</span> DECR b:stock
QUEUED
<span class="token comment">#实际执行事务</span>
<span class="token number">127.0</span>.0.1:637<span class="token operator"><span class="token file-descriptor important">9</span>&gt;</span> EXEC
<span class="token number">1</span><span class="token punctuation">)</span> <span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">4</span>
<span class="token number">2</span><span class="token punctuation">)</span> <span class="token punctuation">(</span>integer<span class="token punctuation">)</span> <span class="token number">9</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20231128215438880.png" alt="image-20231128215438880" tabindex="0" loading="lazy"><figcaption>image-20231128215438880</figcaption></figure><h4 id="multi事务的特点" tabindex="-1"><a class="header-anchor" href="#multi事务的特点" aria-hidden="true">#</a> Multi事务的特点</h4><ul><li>Redis在开启事务后，输入的命令会加入到一个队列，只有输入exec才会执行队列的命令</li><li>如果输入错误的命令，并且这个命令在加入队列的时候就被redis监测出来了，那么事务中的命令都不会被执行</li><li>如果输入的命令执行的时候才能看的出来是错的，从而躲避了redis将命令加入队列时的检查，比如 lpop 一个String类型的数据。这时候，错误的命令会被执行，然后返回错误信息，正确的命令也会被执行</li><li>注意，<strong>redis并没有提供事务回滚的机制</strong></li><li>如果开启了AOF，发生宕机的时候，会有<strong>部分命令被记录到AOF日志</strong>中，可以使用 redis-check-aof 工具检查 AOF 日志文件，这个工具可以把未完成的事务操作从 AOF 文件中去除</li></ul><blockquote><p>Multi事务不具备原子性</p></blockquote><ul><li>因为单线程的缘故，其他线程切不进来</li><li>但是如果自身奔溃，还是可能只做了一半</li></ul><h4 id="multi缺点" tabindex="-1"><a class="header-anchor" href="#multi缺点" aria-hidden="true">#</a> Multi缺点</h4><ul><li>事务开启后，每个命令都是一次调用，浪费资源</li><li>这些命令的执行都是有时间的，还需要Watch提前来观察，难用至极</li><li>失败了会中断后续流程，Multi失败会继续</li></ul><h3 id="lua脚本-2" tabindex="-1"><a class="header-anchor" href="#lua脚本-2" aria-hidden="true">#</a> LUA脚本</h3><p>LUA是一种用标准C语言编写的轻量的脚本语言</p><p>设计的目的是为了嵌入应用程序中，从而为应用程序提供灵活的扩展和定制功能</p><p>Redis2.6版本通过内嵌支持LUA环境，执行脚本的常用命令为EVAL</p><p>因为Redis是单线程操作，处理过程中，是不会被打断并且切换到其他处理，所以Redis执行Lua不出异常的情况下，不会被打断</p><h4 id="lua脚本特点" tabindex="-1"><a class="header-anchor" href="#lua脚本特点" aria-hidden="true">#</a> LUA脚本特点</h4><ul><li>可以编写if else这种选择逻辑</li><li>事务中间如果失败，会中断后续执行</li><li>使用方便，开启Lua就可以执行事务，不需要Watch来保证执行开始的状态未改变</li></ul><h4 id="lua脚本语法" tabindex="-1"><a class="header-anchor" href="#lua脚本语法" aria-hidden="true">#</a> Lua脚本语法</h4><h5 id="redis提供的调用函数" tabindex="-1"><a class="header-anchor" href="#redis提供的调用函数" aria-hidden="true">#</a> Redis提供的调用函数</h5><div class="language-lua line-numbers-mode" data-ext="lua"><pre class="language-lua"><code>redis<span class="token punctuation">.</span><span class="token function">call</span><span class="token punctuation">(</span><span class="token string">&#39;命令名称&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;key&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;其他参数&#39;</span><span class="token punctuation">,</span> ···<span class="token punctuation">)</span>
redis<span class="token punctuation">.</span><span class="token function">call</span><span class="token punctuation">(</span><span class="token string">&#39;set&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;name&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;jack&#39;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-lua line-numbers-mode" data-ext="lua"><pre class="language-lua"><code>redis<span class="token punctuation">.</span><span class="token function">call</span><span class="token punctuation">(</span><span class="token string">&#39;set&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;name&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;jack&#39;</span><span class="token punctuation">)</span>
<span class="token keyword">local</span> name <span class="token operator">=</span> redis<span class="token punctuation">.</span><span class="token function">call</span><span class="token punctuation">(</span><span class="token string">&#39;get&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;name&#39;</span><span class="token punctuation">)</span>
<span class="token keyword">return</span> name
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h5 id="redis命令调用脚本" tabindex="-1"><a class="header-anchor" href="#redis命令调用脚本" aria-hidden="true">#</a> Redis命令调用脚本</h5><div class="language-bash line-numbers-mode" data-ext="sh"><pre class="language-bash"><code>EVAL <span class="token string">&quot;脚本内容&quot;</span> <span class="token operator">&lt;</span>脚本需要的Key类型的参数个数<span class="token operator">&gt;</span> <span class="token operator">&lt;</span>key数组<span class="token operator">&gt;</span> <span class="token operator">&lt;</span>argv数组<span class="token operator">&gt;</span>
EVAL <span class="token string">&quot;return redis.call(&#39;set&#39;, KEYS[1], ARGV[1])&quot;</span> <span class="token number">1</span> name jack
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h5 id="分布式锁lua脚本" tabindex="-1"><a class="header-anchor" href="#分布式锁lua脚本" aria-hidden="true">#</a> 分布式锁lua脚本</h5><div class="language-lua line-numbers-mode" data-ext="lua"><pre class="language-lua"><code><span class="token comment">-- KEYS[1]就是锁的key，ARGV[1]就是当前线程标识(owner)</span>
<span class="token comment">-- 获取锁中的标识，判断是否与当前线程标识一致</span>
<span class="token keyword">if</span><span class="token punctuation">(</span>redis<span class="token punctuation">.</span><span class="token function">call</span><span class="token punctuation">(</span><span class="token string">&#39;GET&#39;</span><span class="token punctuation">,</span> KEY<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token operator">==</span> ARGV<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token keyword">then</span>
    <span class="token comment">-- 一致，删除锁</span>
	<span class="token keyword">return</span> redis<span class="token punctuation">.</span><span class="token function">call</span><span class="token punctuation">(</span><span class="token string">&#39;DEL&#39;</span><span class="token punctuation">,</span> KEYS<span class="token punctuation">[</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
<span class="token keyword">end</span>
<span class="token comment">-- 不一致，返回</span>
<span class="token keyword">return</span> <span class="token number">0</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="消息队列" tabindex="-1"><a class="header-anchor" href="#消息队列" aria-hidden="true">#</a> 消息队列</h2><h3 id="消息队列基础" tabindex="-1"><a class="header-anchor" href="#消息队列基础" aria-hidden="true">#</a> 消息队列基础</h3><blockquote><p>什么是消息队列</p></blockquote><p>存放消息的队列</p><p>最简单的消息队列模型包括3个角色</p><ul><li>消息队列：存储和管理消息，也称为消息代理</li><li>生产者：发送消息到消息队列</li><li>消费者：从消息队列获取消息并处理消息</li></ul><p>一般生产环境中会使用现成的mq，如kafka，rabbitmq等</p><h3 id="基于list实现消息队列" tabindex="-1"><a class="header-anchor" href="#基于list实现消息队列" aria-hidden="true">#</a> 基于LIst实现消息队列</h3><p>Redis的list数据结构是一个双向链表，很容易模拟出队列效果。</p><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20231128231155661.png" alt="image-20231128231155661" tabindex="0" loading="lazy"><figcaption>image-20231128231155661</figcaption></figure><ol><li>生产者使用RPUSH往队列末尾增加消息</li><li>消费者用LPOP从对头取出元素</li></ol><blockquote><p>消费者不清楚LPOP的时机，所以只能不停轮询 Redis提供了阻塞版本的POP命令，BRPOP，BLPOP 使用BLPOP从队头消费，如果没有消息，就会阻塞，直到达到超时时间</p></blockquote><p>优点：</p><ul><li>利用Redis存储，不受限于JVM内存上限</li><li>基于Redis的持久化机制，数据安全性有保证（相对于pubsub来说）</li><li>可以满足消息有序性</li></ul><p>缺点：</p><ul><li>无法避免消息丢失：使用以上命令，消费消息后直接删除，取出消息后服务宕机，那么任务就丢失了</li><li>只支持单消费者：发送的消息被一个消费者拿走了就移除了，无法实现一条消息被多个消费者消费的需求</li></ul><h3 id="基于pub-sub的消息队列" tabindex="-1"><a class="header-anchor" href="#基于pub-sub的消息队列" aria-hidden="true">#</a> 基于Pub/Sub的消息队列</h3><p>PubSub（发布订阅）是Redis2.0版本引入的消息传递模型。顾名思义，消费者可以订阅一个或多个channel，生产者向对应channel发送消息后，所有订阅者都能收到相关消息。</p><ul><li><code>SUBSCRIBE channel [channel]</code>：订阅一个或多个频道</li><li><code>PUBLISH channel msg</code>：向一个频道发送消息</li><li><code>PSUBSCRIBE pattern[pattern]</code> ：订阅与pattern格式匹配的所有频道</li></ul><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20231129000814410.png" alt="image-20231129000814410" tabindex="0" loading="lazy"><figcaption>image-20231129000814410</figcaption></figure><p>优点：</p><ul><li>采用发布订阅模型，支持多生产、多消费</li></ul><p>缺点：</p><ul><li>不支持数据持久化：pubsub本质就是用来消息发送的，不存数据</li><li>无法避免消息丢失：如果消息频道没有被任何人订阅，那么消息就直接丢失，消息不会在redis中保存</li><li>消息堆积有上限，超出时数据丢失：发送消息，如果有消费者监听，会在消费者那里用一个缓存区，把消息缓存下来，消费者的缓存空间是有上限的</li></ul><blockquote><p>与List实现的消息队列相比：</p><p>pubsub的消息队列可以支持多生产多消费，但是不能对消息进行持久化，所以并不是一个十分完善的方案</p></blockquote><h3 id="基于stream的消息队列" tabindex="-1"><a class="header-anchor" href="#基于stream的消息队列" aria-hidden="true">#</a> 基于Stream的消息队列</h3><p>Redis 5.0 推出了 Stream 类型也是此版本最重要的功能，用于完美地实现消息队列，它支持消息的持久化、支持自动生成全局唯一 ID、支持 ack 确认消息的模式、支持消费组模式等，让消息队列更加的稳定和可靠。</p><ul><li><code>XADD</code>：插入消息，保证有序，可以自动生成全局唯一 ID；</li><li><code>XLEN</code> ：查询消息长度；</li><li><code>XREAD</code>：用于读取消息，可以按 ID 读取数据；</li><li><code>XDEL</code> ： 根据消息 ID 删除消息；</li><li><code>DEL</code> ：删除整个 Stream；</li><li><code>XRANGE</code> ：读取区间消息</li><li><code>XREADGROUP</code>：按消费组形式读取消息；</li><li><code>XPENDING</code> 和 <code>XACK</code>： <ul><li><code>XPENDING</code> 命令可以用来查询每个消费组内所有消费者「已读取、但尚未确认」的消息；</li><li><code>XACK</code> 命令用于向消息队列确认消息处理已完成；</li></ul></li></ul><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20231129004613316.png" alt="image-20231129004613316" tabindex="0" loading="lazy"><figcaption>image-20231129004613316</figcaption></figure><p>优点：</p><ul><li>解决了<code>List</code>无法支持多生产多消费</li><li>解决了<code>pub/sub</code>无法持久化存储消息</li><li>使用<code>PENDING list</code>内部队列和<code>XACK</code>确认命令，解决了消息的确认问题，同时支持消息回溯，防止消息异常丢失</li><li>可以实现阻塞读取</li></ul><p>缺点：</p><ul><li>Redis 本身可能会丢数据；</li><li>面对消息挤压，内存资源会紧张；</li></ul><p>技术选型</p><ul><li>如果你的业务场景足够简单，对于数据丢失不敏感，而且消息积压概率比较小的情况下，把 Redis 当作队列是完全可以的。</li><li>如果你的业务有海量消息，消息积压的概率比较大，并且不能接受数据丢失，那么还是用专业的消息队列中间件吧。</li></ul><h3 id="三种实现方式的对比" tabindex="-1"><a class="header-anchor" href="#三种实现方式的对比" aria-hidden="true">#</a> 三种实现方式的对比</h3><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20231129005956834.png" alt="image-20231129005956834" tabindex="0" loading="lazy"><figcaption>image-20231129005956834</figcaption></figure><h2 id="限流器" tabindex="-1"><a class="header-anchor" href="#限流器" aria-hidden="true">#</a> 限流器</h2><h3 id="限流器基础" tabindex="-1"><a class="header-anchor" href="#限流器基础" aria-hidden="true">#</a> 限流器基础</h3><blockquote><p>什么是限流器</p></blockquote><p>不管是什么后台服务，每秒能处理的请求个数总有极限。如果超过这个极限，轻则让服务变得缓慢，重则直接干跨业务，因此我们需要使用一些手段限制请求的发送频率。</p><p>一般来说，我们可以限制总的频率，也可以更精细一点，比如针对用户、IP等维度进行配额分发，思路都是相同的。</p><p>在下面的讲述中，实际底层都是以Redis来做存储的，这也是生产中常见的做法</p><h3 id="计数器算法" tabindex="-1"><a class="header-anchor" href="#计数器算法" aria-hidden="true">#</a> 计数器算法</h3><h4 id="实现思路" tabindex="-1"><a class="header-anchor" href="#实现思路" aria-hidden="true">#</a> 实现思路</h4><ol><li>设定一个阈值，在单位之间内的请求不可超过这个阈值</li><li>比如设置阈值为1000个请求，单位时间为1s <ol><li>如果1s内的请求超过了1000，则拒绝访问，1s结束后再重置请求量为0</li></ol></li><li>具体实现中 <ol><li>单机限流可以用一个整数+时间戳记录。时间戳到达上限，整数就从0开始，计数达到阈值则拒绝，使用变量来实现，这时候好像还用不到Redis，我认为可以使用前端来实现这个限流，定义整数+时间戳两个变量来记录</li><li>分布式使用Redis的天然过期时间，同时使用Lua脚本保证原子性</li></ol></li></ol><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20231129104156679.png" alt="image-20231129104156679" tabindex="0" loading="lazy"><figcaption>image-20231129104156679</figcaption></figure><h4 id="缺点-请求突刺" tabindex="-1"><a class="header-anchor" href="#缺点-请求突刺" aria-hidden="true">#</a> 缺点：请求突刺</h4><blockquote><p>计数器算法的优点是实现简单，缺点是有请求突刺，可能在单位时间内会出现请求量超过阈值的情况</p></blockquote><p>比如我们希望一段时间的请求数最多是2000，时间窗口是t1开始，到t2结束然后是t2开始，到t3结束，那先在t2前一瞬间发送1000的请求，t2后一瞬间又立即发1000个请求，那么在t1-t2，t2-t3这两个时间窗口中，虽然都满足了每分钟不超过1000这个规则，但实际上在t2前后，这一分钟的请求已达2000。</p><blockquote><ul><li>临近t2前发送1000请求，t2结束马上又发了1000，都满足了时间窗口内1000请求</li><li>那么在这两个时间窗口，都会有1000的请求到达服务器</li><li>但是这2000请求发送的时间刚好在两个时间窗口，但又非常临近，所以还是会造成服务器的负担</li></ul></blockquote><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20231129104220681.png" alt="image-20231129104220681" tabindex="0" loading="lazy"><figcaption>image-20231129104220681</figcaption></figure><h3 id="滑动窗口算法" tabindex="-1"><a class="header-anchor" href="#滑动窗口算法" aria-hidden="true">#</a> 滑动窗口算法</h3><blockquote><p>计数器算法的优化，计数器算法在突刺下无法满足单位时间内请求不得超过阈值的要求，而这是滑动窗口在任意的窗口粒度下都可以解决的问题，实际开发如果要在计数器和滑动窗口二选一，必选滑动窗口</p></blockquote><p><strong>计数器算法突刺问题本质</strong></p><ul><li>是将一段时间看成一个整体，而不是以基于物理时间来看时间窗口，这就导致有漏洞可循。</li></ul><p><strong>优化计数器算法</strong></p><ul><li>以当前物理时间为基点往前看，看基于当前时间的时间窗口，是否超过阈值，超过阈值就拒绝请求，问题就迎刃而解了。</li></ul><p><strong>举例</strong></p><ul><li>我们相当于是将一个时间窗口，分为多个格子，比如20s一个格子，那我们一分钟的时间窗口，就被分为了三个格子。每次基于当前时间，往前看三个格子就是当前的滑动请求量。</li><li>以时间粒度1小时举个例子如果是普通窗口，时间区间就是1:00-2:00,2:0-3:00这样。如果有人在2:00前后搞事情，那就会造成突刺，突破上限。</li><li>而滑动窗口始终是基于当前，如果现在是2:00，那窗口就是1:00-2:00，如果是2:15，窗口就是1:15-2:15。</li><li>如果你在2点前几乎怼满了一波，那你必须得等当前时间滑得够远，你才怼第二波，这就解决了突刺。也就是说，当滑动窗口的左边界越过了2点，才可以再发请求</li></ul><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20231129104318495.png" alt="image-20231129104318495" tabindex="0" loading="lazy"><figcaption>image-20231129104318495</figcaption></figure><h3 id="漏桶算法" tabindex="-1"><a class="header-anchor" href="#漏桶算法" aria-hidden="true">#</a> 漏桶算法</h3><h4 id="实现思路-1" tabindex="-1"><a class="header-anchor" href="#实现思路-1" aria-hidden="true">#</a> 实现思路</h4><ul><li>有一个桶，入水速度不定，出水速度由于管口较小，都是一滴一滴下来所以速度恒定。</li><li>如果桶满了，我们就不能再往里面加水了。</li><li>入口流量频率不变，出口速率始终恒定，我们利用这个特性，就可以做到均匀限频。</li></ul><h4 id="缺点-1" tabindex="-1"><a class="header-anchor" href="#缺点-1" aria-hidden="true">#</a> 缺点</h4><ul><li>我们无法精确判断网络带宽或处理能力。一般来说都只能设置一个相对比较小的流量目标，比如800/s。</li><li>如果产生了一波突发流量，经过了漏桶算法后，依然会以恒定的目标码率慢慢地发送。就算我们的服务有足够的实力，也不能让它快速处理了。所以说，漏桶算法<strong>无法充分用满性能资源</strong></li></ul><h4 id="解决方式" tabindex="-1"><a class="header-anchor" href="#解决方式" aria-hidden="true">#</a> 解决方式</h4><ol><li>动态调节水滴速度(就像输液瓶一样)：通过对后端进行不断试探，尽可能始终维持在性能处理的极致 <ol><li>弊端在于带来了更多的复杂性和耦合性，属于特定优化了</li></ol></li><li>用另一种桶，令牌桶</li></ol><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20231129104348344.png" alt="image-20231129104348344" tabindex="0" loading="lazy"><figcaption>image-20231129104348344</figcaption></figure><h3 id="令牌桶算法" tabindex="-1"><a class="header-anchor" href="#令牌桶算法" aria-hidden="true">#</a> 令牌桶算法</h3><h4 id="实现思路-2" tabindex="-1"><a class="header-anchor" href="#实现思路-2" aria-hidden="true">#</a> 实现思路</h4><ul><li>有一个桶，桶里均匀产生令牌，如果令牌把桶塞满了，就不会再生产令牌。</li><li>请求过来的时候，需要先拿到桶里的令牌，才能做后续处理，如果桶里没有令牌了，可以选择放弃或等待。</li><li>举个例子: <ul><li>我们桶里面能放1000个令牌，1ms产生一个令牌，那1s就可以装满这个桶，请求要处理，先从桶里拿令牌，这样1s就能处理1000次。</li></ul></li></ul><h4 id="优点-1" tabindex="-1"><a class="header-anchor" href="#优点-1" aria-hidden="true">#</a> 优点</h4><ul><li>令牌桶算法很像生产消费模式，同时出口流量也很稳定。</li><li>令牌桶算法能够在请求量小的时候，积累令牌，这种模式在限制数据的平均传输速率的同时还允许某种程度的突发传输。 <ul><li>这里的突发传出应该是相对于漏桶算法的绝对匀速的请求量而言的，令牌桶可以在短时间内接受突发的大量请求</li><li>这里的限制数据平均传输速率，相对于计数器、滑动窗口算法而言，他们只要单位时间内小于请求阈值就行，没有对请求的速度进行控制，而令牌桶通过令牌数量对流速进行了控制，比如突然消耗掉很多令牌之后，就只能慢慢等令牌生产来慢慢发送请求</li></ul></li></ul><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20231129104405646.png" alt="image-20231129104405646" tabindex="0" loading="lazy"><figcaption>image-20231129104405646</figcaption></figure><h3 id="四种算法对比" tabindex="-1"><a class="header-anchor" href="#四种算法对比" aria-hidden="true">#</a> 四种算法对比</h3><ul><li>**复杂性：**令牌桶 &gt;= 漏桶 &gt;滑动窗&gt;计数器但实际上限流算法都不复杂，并且都有现成的实现，生产时候还是以实际需求为主，复杂性不用考虑太多。</li><li>**均匀度：**令牌桶和漏桶，其实都属于流量整形算法，流量整形是说指不管流量到达的速率多么不稳定，在接收流量后，都可以将其匀速输出。而滑动窗口算法，计数器算法，只是限制了一段时间的个数，没有流量整形的效率，均匀度会低一些。</li><li>**容忍突发流量：**指的是限流策略允许流量在短时间内突增，且在突增结束后不会影响后续流量的正常限流，这一块的话只有令牌桶支持</li></ul><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20231129104424511.png" alt="image-20231129104424511" tabindex="0" loading="lazy"><figcaption>image-20231129104424511</figcaption></figure><h3 id="生产中的选择" tabindex="-1"><a class="header-anchor" href="#生产中的选择" aria-hidden="true">#</a> 生产中的选择</h3><ul><li>在实际生产中，令牌桶因为其均匀性及突发流量容忍性，更受青睐。 <ul><li>腾讯云团队，阿里线上管控体系，Shopee 金融团队，都使用了令牌桶来做限流。</li></ul></li><li>而唯一可以和令牌桶 battle 的漏桶，没有针对突发流量的处理，严格限制，个人感觉这不是缺陷而是特性，并不是每个场景，都需要支持突发流量的，如果要很严格限定流量，漏桶会是最好的选择。</li><li>至于计数器和滑动窗口算法，优势就是简单，但限流算法实际都不复杂，所以这个优势就很不明显了，生产上不建议使用。限流是开发领域一个非常重要的话题，毕竟流控做好了，才不容易过载，才能有个稳定的系统。</li></ul><h2 id="特殊key" tabindex="-1"><a class="header-anchor" href="#特殊key" aria-hidden="true">#</a> 特殊KEY</h2><h3 id="大key" tabindex="-1"><a class="header-anchor" href="#大key" aria-hidden="true">#</a> 大Key</h3><h4 id="判断依据" tabindex="-1"><a class="header-anchor" href="#判断依据" aria-hidden="true">#</a> 判断依据</h4><p>通常会<strong>以Key的大小和Key中成员的数量来综合判定</strong></p><ul><li><strong>Key本身数据量过大</strong><ul><li>String类型的Key，值为5MB</li></ul></li><li>Key中<strong>成员数量过多</strong><ul><li>ZSet类型的Key，成员数量为10000个</li></ul></li><li>Key中<strong>成员数据量过大</strong><ul><li>Hash类型的Key，成员数量虽然只有1000个，但value总大小为100MB</li></ul></li></ul><h4 id="造成问题" tabindex="-1"><a class="header-anchor" href="#造成问题" aria-hidden="true">#</a> 造成问题</h4><ul><li><p>客户端<strong>执行命令的时间变长</strong></p></li><li><p>内存达到maxmemory后引发<strong>操作阻塞</strong>或<strong>驱逐重要Key</strong>，甚至引发<strong>内存溢出</strong>(Out Of Memory)</p></li><li><p>集群架构下，某个数据分片的<strong>内存使用率</strong>可能远超其他数据分片，无法使数据分片的内存资源达到均衡</p></li><li><p>对大key的<strong>读请求</strong>会使Redis实例的<strong>带宽使用率</strong>被占满，导致自身服务变慢，同时波及其相关的服务</p></li><li><p>对大Key执行<strong>删除操作</strong>，容易造成主库较长时间的<strong>阻塞</strong>，进而引发同步中断或主从切换</p></li></ul><h4 id="产生的原因" tabindex="-1"><a class="header-anchor" href="#产生的原因" aria-hidden="true">#</a> 产生的原因</h4><ul><li>在不适用的场景下使用Redis，容易造成Key的Value过大 <ul><li>如使用String类型的Key存放大体积的二进制文件型数据</li></ul></li><li>业务上线前规划设计不足，没有对Key中成员进行合理的划分，造成个别Key中的成员过多</li><li>未定期清理无效数据，造成如HASH类型Key中的成员不断增加</li><li>使用LIST类型Key的业务消费侧发生代码故障，造成对应的Key成员只增不减</li></ul><h4 id="解决方案-1" tabindex="-1"><a class="header-anchor" href="#解决方案-1" aria-hidden="true">#</a> 解决方案</h4><ol><li>数据存在Mc中 <ul><li>可以设计一个缓存阈值，当value的长度超过阈值，则对内容启用压缩，让KV尽量保持小的size</li><li>其次评估大Key所占的比例，在Mc启动之初， 就预写足够数据的大key <ul><li>让Mc预先分配足够多的truck size较大的slab，确保后面系统运行的时候，大Key有足够的空间进行缓存</li></ul></li></ul></li></ol><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20231129151418610.png" alt="image-20231129151418610" tabindex="0" loading="lazy"><figcaption>image-20231129151418610</figcaption></figure><ol start="2"><li>数据存在Redis中 <ul><li>比如业务数据存 set 格式，大 key 对应的 set 结构有几千几万个元素，这种写入 Redis 时会消耗很长的时间，导致 Redis 卡顿。</li><li>此时，可以扩展新的数据结构，同时让 client 在这些大 key 写缓存之前，进行序列化构建，然后通过 restore 一次性写入</li></ul></li></ol><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20231129151611828.png" alt="image-20231129151611828" tabindex="0" loading="lazy"><figcaption>image-20231129151611828</figcaption></figure><ol start="3"><li>将大Key分为多个key，尽量减少大Key的存在 <ul><li>由于大Key一旦穿透到DB，加载耗时很大，所以可以对这些大Key进行特殊照顾 <ul><li>设置较长的过期时间</li><li>内存淘汰的时候尽量不要淘汰这些大key</li></ul></li></ul></li></ol><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20231129151926405.png" alt="image-20231129151926405" tabindex="0" loading="lazy"><figcaption>image-20231129151926405</figcaption></figure><h3 id="热key" tabindex="-1"><a class="header-anchor" href="#热key" aria-hidden="true">#</a> 热KEY</h3><h4 id="判断依据-1" tabindex="-1"><a class="header-anchor" href="#判断依据-1" aria-hidden="true">#</a> 判断依据</h4><p>通常以其接收到的<strong>Key被请求的频率</strong>来判定</p><ul><li><strong>QPS集中在特定的Key</strong>：Redis实例的总QPS（每秒查询率）为10000，而其中一个Key的QPS达到了7000</li><li><strong>带宽使用率集中在特定的Key</strong>：对一个拥有上千成员且总大小为1MB的HASH key每秒发送大量的HGETALL请求 <ul><li>指定Key的带宽使用率高，说明该Key数据的频繁传输占用网络带宽</li></ul></li><li><strong>CPU使用时间占比集中在特定的Key</strong>：对一个拥有数万个成员的Key（ZSet类型）每秒发送大量的ZRANGE操作请求 <ul><li>特定Key的CPU使用时间占比高，表示该Key操作复杂占用了大量的CPU资源</li></ul></li></ul><h4 id="造成问题-1" tabindex="-1"><a class="header-anchor" href="#造成问题-1" aria-hidden="true">#</a> 造成问题</h4><ul><li><strong>占用大量的CPU资源</strong>，影响其他请求并导致整体性能降低。</li><li>集群架构下，产生访问倾斜，即<strong>某个数据分片被大量访问</strong>，而其他数据分片处于空闲状态，可能引起该数据分片的<strong>连接数被耗尽，新的连接建立请求被拒绝</strong>等问题。</li><li>在<strong>抢购或秒杀</strong>场景下，可能因商品对应库存Key的请求量过大，超出Redis处理能力造成<strong>超卖</strong>。</li><li>热Key的请求压力数量超出Redis的承受能力易造成<strong>缓存击穿</strong>，即大量请求将被直接指向后端的存储层，导致存储访问量激增甚至宕机，从而影响其他业务。</li></ul><h4 id="产生的原因-1" tabindex="-1"><a class="header-anchor" href="#产生的原因-1" aria-hidden="true">#</a> 产生的原因</h4><ul><li>预期外的访问量陡增 <ul><li>如突然出现的爆款商品</li><li>访问量暴涨的热点新闻</li><li>直播间某主播搞活动带来的大量刷屏点赞</li><li>游戏中某区域发生多个工会之间的战斗涉及大量玩家等。</li></ul></li></ul><ul><li>流量集中打在一个缓存节点机器，这个缓存机器很容易被打到物理网卡、带宽、CPU 的极限，从而导致缓存访问变慢、卡顿。</li></ul><h4 id="解决方案-2" tabindex="-1"><a class="header-anchor" href="#解决方案-2" aria-hidden="true">#</a> 解决方案</h4><blockquote><p>要解决热Key问题，首先需要找出热Key</p></blockquote><ul><li>对于重要节假日、线上促销活动、集中推送这些提前已知的事情，可以提前评估出可能的热 key 来。</li><li>而对于突发事件，无法提前评估，可以通过 Spark，对应流任务进行实时分析，及时发现新发布的热点 key。</li><li>而对于之前已发出的事情，逐步发酵成为热 key 的，则可以通过 Hadoop 对批处理任务离线计算，找出最近历史数据中的高频热 key。</li></ul><blockquote><p>**热Key的解决方案 **</p></blockquote><ol><li>分散处理 <ul><li>可以将一个热Key分散成多个热Key，分出来的这些多个热Key会存在多个缓存节点</li><li>客户端请求的时候会随机访问其中某个后缀的热key</li><li>这样就可以实现把热Key的请求打散，避免一个缓存节点过载</li></ul></li></ol><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20231129150126704.png" alt="image-20231129150126704" tabindex="0" loading="lazy"><figcaption>image-20231129150126704</figcaption></figure><ol start="2"><li><p>多副本+多级结合的缓存架构设计</p></li><li><p>实时监控+快速扩容</p><ul><li><p>SLA是是指服务级别协议（Service Level Agreement）。它是一种合同、约定或协议，用于定义服务提供商与客户之间的服务水平和性能指标。</p></li><li><p>缓存系统中，通过监控体系对缓存的SLA进行实时监控意味着跟踪并记录缓存系统的性能指标，例如命中率、延迟等。</p></li><li><p>扩容包括垂直扩容和水平扩容</p><ul><li>垂直扩容：垂直扩容是增加单个服务器的资源，例如增加服务器的内存容量。</li><li>水平扩容：增加缓存服务器的数量，以分担负载并提高整体系统性能</li></ul></li></ul></li><li><p>最后，业务端还可以使用本地缓存，将这些热 key 记录在本地缓存，来减少对远程缓存的冲击。</p><ul><li><p>本地缓存：指将数据存储在应用程序所在的服务器或客户端上</p></li><li><p>服务器端：项目和缓存中间件部署在同一个服务器上，就算是本地缓存</p></li><li><p>客户端：客户端（例如浏览器、移动应用等）中存储数据副本，以便在后续的请求中可以直接从客户端获取数据，而不必再次向服务器发送请求</p></li></ul></li></ol>`,556),t=[l];function o(p,r){return n(),i("div",null,t)}const u=a(s,[["render",o],["__file","Redis应用场景.html.vue"]]);export{u as default};
