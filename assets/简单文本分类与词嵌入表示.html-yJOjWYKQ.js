import{_ as n}from"./plugin-vue_export-helper-x3n3nnut.js";import{o as s,c as a,f as t}from"./app-OTaO6_y0.js";const p={},e=t(`<h1 id="简单文本分类与词嵌入表示" tabindex="-1"><a class="header-anchor" href="#简单文本分类与词嵌入表示" aria-hidden="true">#</a> 简单文本分类与词嵌入表示</h1><h2 id="文本表示与词嵌入" tabindex="-1"><a class="header-anchor" href="#文本表示与词嵌入" aria-hidden="true">#</a> 文本表示与词嵌入</h2><h3 id="文本的理解" tabindex="-1"><a class="header-anchor" href="#文本的理解" aria-hidden="true">#</a> 文本的理解</h3><ul><li><p>文本是常用的序列化数据类型之一。文本数据可以看作是一个字符序列或词的序列。对于大多数问题，我们都将文本看作词序列</p></li><li><p>深度学习序列模型（如RNN及其变体）能够较好的对序列化数据建模</p></li><li><p>深度学习序列模型（如RNN及其变体）可以解决类似一下领域中的问题</p><ul><li>自然语言理解</li><li>文献分类，情感分类</li><li>问答系统等</li></ul></li></ul><h3 id="文本向量化方法" tabindex="-1"><a class="header-anchor" href="#文本向量化方法" aria-hidden="true">#</a> 文本向量化方法</h3><ul><li><p>深度学习模型并不能理解文本，因此需要将文本转化为数值的表示形式</p></li><li><p>将文本转换为数值表示形式的过程成为向量化过程，可以用不同的方式来完成</p><ul><li><p>传统机器学习：tf-idf算法</p></li><li><p>独热编码：one-hot或者k-hot</p></li><li><p>散列编码（哈希函数）</p></li><li><p>文本词嵌入（word embedding）</p></li></ul></li></ul><h3 id="词嵌入概念" tabindex="-1"><a class="header-anchor" href="#词嵌入概念" aria-hidden="true">#</a> 词嵌入概念</h3><ul><li><p>词嵌入是单词的一种数值化表示方式</p></li><li><p>一般情况下会将单词映射到一个高维的向量中（词向量）来代表这个单词</p></li><li><p>对于词向量，我们可以使用余弦相似度在计算机中来判断单词之间的距离</p></li><li><p>词嵌入实际上是将各个单词在预定的向量空间中表示为实值向量的一类技术</p></li><li><p>每一个单词被映射成一个向量（初始随机化），并且这个向量可以通过神经网络的方式来学习更新。因此这项技术基本集中应用在深度学习领域</p></li><li><p>词嵌入用密集的分布式向量来表示每个单词</p></li><li><p>与one-hot这样的编码相比，使用词嵌入表示的单词向量往往只有几十或者几百维度。极大减小了计算和存储量</p></li><li><p>词向量表示方式依赖于单词的使用习惯，这就使得具有相似使用方式的单词具有相似的表示形式</p></li><li><p>词嵌入是从文本语料中学习到的一种将单词表示为预定义大小的实值向量形式</p></li><li><p>学习过程一般与某个神经网络模型任务一同进行，比如文档分类</p></li></ul><h3 id="词嵌入的方法" tabindex="-1"><a class="header-anchor" href="#词嵌入的方法" aria-hidden="true">#</a> 词嵌入的方法</h3><ul><li><p><strong>Word2vec</strong></p><ul><li>是一种能有效从文本语料库中学习到独立词嵌入的统计方法</li></ul></li><li><p><strong>GloVe</strong></p><ul><li>GloVe算法是对于Word2Vec方法的拓展，更为有效</li></ul></li><li><p>使用词嵌入</p><ul><li>在自然语言处理项目中使用单词嵌入时，可以选择两种方式 <ul><li>自己学一个词嵌入</li><li>使用别人训练好的词嵌入</li></ul></li></ul></li></ul><h3 id="文本的词嵌入表示处理流程" tabindex="-1"><a class="header-anchor" href="#文本的词嵌入表示处理流程" aria-hidden="true">#</a> 文本的词嵌入表示处理流程</h3><ul><li><p>文本数据在表示为独热编码和词嵌入之前，首先需要表示成token</p></li><li><p>每个较小的文本单元称为token，将文本分解成token的过程成为分词（tokenization）</p></li><li><p>一旦将文本数据转换为token序列，那么就需要将每一个token映射到向量</p></li><li><p>one-hot编码和词嵌入是将token映射到向量最流行的两种方法</p></li></ul><h3 id="文本表示代码实现" tabindex="-1"><a class="header-anchor" href="#文本表示代码实现" aria-hidden="true">#</a> 文本表示代码实现</h3><h4 id="分词并创建词表" tabindex="-1"><a class="header-anchor" href="#分词并创建词表" aria-hidden="true">#</a> 分词并创建词表</h4><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>vocab <span class="token operator">=</span> <span class="token builtin">dict</span><span class="token punctuation">(</span><span class="token punctuation">(</span>word<span class="token punctuation">,</span> index<span class="token punctuation">)</span> <span class="token keyword">for</span> index<span class="token punctuation">,</span> word <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>np<span class="token punctuation">.</span>unique<span class="token punctuation">(</span>s<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
s <span class="token operator">=</span> <span class="token punctuation">[</span>vocab<span class="token punctuation">.</span>get<span class="token punctuation">(</span>w<span class="token punctuation">)</span> <span class="token keyword">for</span> w <span class="token keyword">in</span> s<span class="token punctuation">.</span>split<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">]</span> <span class="token comment"># 将语料用词表表示</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="one-hot" tabindex="-1"><a class="header-anchor" href="#one-hot" aria-hidden="true">#</a> one-hot</h4><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>b <span class="token operator">=</span> np<span class="token punctuation">.</span>zeros<span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token builtin">len</span><span class="token punctuation">(</span>vocab<span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 创建一个全零矩阵，行数为总词数，列数为词表长度</span>
<span class="token keyword">for</span> index <span class="token punctuation">,</span> i <span class="token keyword">in</span> <span class="token builtin">enumerate</span><span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">:</span> <span class="token comment"># 将每个词对应的序号除填1</span>
    b<span class="token punctuation">[</span>index<span class="token punctuation">,</span> i<span class="token punctuation">]</span> <span class="token operator">=</span> <span class="token number">1</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="wordembedding" tabindex="-1"><a class="header-anchor" href="#wordembedding" aria-hidden="true">#</a> WordEmbedding</h4><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 调用pytorch内置的Embedding层 num_embeddings -&gt; 词表长度, embedding_dim -&gt; 词向量长度</span>
em <span class="token operator">=</span> torch<span class="token punctuation">.</span>nn<span class="token punctuation">.</span>Embedding<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>vocab<span class="token punctuation">)</span><span class="token punctuation">,</span> <span class="token number">20</span><span class="token punctuation">)</span>
s_em <span class="token operator">=</span> em<span class="token punctuation">(</span>torch<span class="token punctuation">.</span>LongTensor<span class="token punctuation">(</span>s<span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="文本分类实例" tabindex="-1"><a class="header-anchor" href="#文本分类实例" aria-hidden="true">#</a> 文本分类实例</h2><h3 id="文本分类预处理的步骤" tabindex="-1"><a class="header-anchor" href="#文本分类预处理的步骤" aria-hidden="true">#</a> 文本分类预处理的步骤</h3><ul><li>分词</li><li>创建词表</li><li>词嵌入表示 <ul><li><code>torch.nn.Embedding()</code></li><li><code>torch.nn.EmbeddingBag()</code>聚合方法 <ul><li>对一个序列中文字的<code>embeding</code>输出做聚合</li><li>求和，均值，最大值等</li><li>当我们输入一个文本序列到EmbedingBag层时，这个层会将序列中每个单词作词嵌入表示，并将结果根据指定的聚合计算方法计算后作为最后的输出</li></ul></li></ul></li></ul><h3 id="简单文本分类" tabindex="-1"><a class="header-anchor" href="#简单文本分类" aria-hidden="true">#</a> 简单文本分类</h3><ul><li>简单文本分类模型中可以使用EmbeddingBag层加Linear层快速创建文本分类模型</li><li>这样的模型创建起来分词便捷，计算效率也很高</li></ul><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20230826111735682.png" alt="image-20230816203511380" tabindex="0" loading="lazy"><figcaption>image-20230816203511380</figcaption></figure><h3 id="代码实现" tabindex="-1"><a class="header-anchor" href="#代码实现" aria-hidden="true">#</a> 代码实现</h3><h4 id="数据预处理" tabindex="-1"><a class="header-anchor" href="#数据预处理" aria-hidden="true">#</a> 数据预处理</h4><ul><li>从torchtext中取出IMDB数据集 -&gt; 用iter()方法将其转化为一个迭代器 <ul><li><code>root</code>：该数据集的下载路径（默认在c盘）</li><li><code>split</code>：切分训练集和验证集</li></ul></li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>train_iter <span class="token operator">=</span> <span class="token builtin">iter</span><span class="token punctuation">(</span>torchtext<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>IMDB<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">&#39;./&#39;</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">&#39;train&#39;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
test_iter <span class="token operator">=</span> <span class="token builtin">iter</span><span class="token punctuation">(</span>torchtext<span class="token punctuation">.</span>datasets<span class="token punctuation">.</span>IMDB<span class="token punctuation">(</span>root<span class="token operator">=</span><span class="token string">&#39;./&#39;</span><span class="token punctuation">,</span> split<span class="token operator">=</span><span class="token string">&#39;test&#39;</span><span class="token punctuation">)</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>将数据集中标签为1的设为neg，其他的设为pos</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>train_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">&#39;neg&#39;</span> <span class="token keyword">if</span> label <span class="token operator">==</span> <span class="token number">1</span> <span class="token keyword">else</span> <span class="token string">&#39;pos&#39;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> text<span class="token punctuation">)</span>  <span class="token keyword">for</span> label<span class="token punctuation">,</span> text <span class="token keyword">in</span>  <span class="token builtin">list</span><span class="token punctuation">(</span>train_iter<span class="token punctuation">)</span><span class="token punctuation">]</span>
test_data <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token punctuation">(</span><span class="token string">&#39;neg&#39;</span> <span class="token keyword">if</span> label <span class="token operator">==</span> <span class="token number">1</span> <span class="token keyword">else</span> <span class="token string">&#39;pos&#39;</span><span class="token punctuation">)</span><span class="token punctuation">,</span> text<span class="token punctuation">)</span>  <span class="token keyword">for</span> label<span class="token punctuation">,</span> text <span class="token keyword">in</span>  <span class="token builtin">list</span><span class="token punctuation">(</span>test_iter<span class="token punctuation">)</span><span class="token punctuation">]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>初始化torchtext内置的分词工具</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>tokenizer <span class="token operator">=</span> get_tokenizer<span class="token punctuation">(</span><span class="token string">&#39;basic_english&#39;</span><span class="token punctuation">)</span> 
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>tokenizer<span class="token punctuation">(</span><span class="token string">&#39;I love u&#39;</span><span class="token punctuation">)</span>
<span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token punctuation">[</span><span class="token string">&#39;i&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;love&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;u&#39;</span><span class="token punctuation">]</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>从迭代器创建词表 <ul><li><code>iterator</code> -&gt; 迭代器</li><li><code>specials</code> -&gt; 在vocab中加入特殊字符：<code>[&#39;&lt;pad&gt;&#39;, &#39;&lt;unk&gt;&#39;]</code>（占位符和未知字符）</li><li><code>min_freq</code> -&gt; 过滤词频小于3的单词</li></ul></li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token comment"># 创建迭代器方法</span>
<span class="token keyword">def</span> <span class="token function">yield_tokens</span><span class="token punctuation">(</span>data<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">for</span><span class="token punctuation">(</span>_<span class="token punctuation">,</span> text<span class="token punctuation">)</span> <span class="token keyword">in</span> data<span class="token punctuation">:</span>
        <span class="token keyword">yield</span> tokenizer<span class="token punctuation">(</span>text<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>vocab <span class="token operator">=</span> build_vocab_from_iterator<span class="token punctuation">(</span>yield_tokens<span class="token punctuation">(</span>train_data<span class="token punctuation">)</span><span class="token punctuation">,</span> specials<span class="token operator">=</span><span class="token punctuation">[</span><span class="token string">&#39;&lt;pad&gt;&#39;</span><span class="token punctuation">,</span> <span class="token string">&#39;&lt;unk&gt;&#39;</span><span class="token punctuation">]</span><span class="token punctuation">,</span> min_freq<span class="token operator">=</span><span class="token number">3</span><span class="token punctuation">)</span>
vocab<span class="token punctuation">.</span>set_default_index<span class="token punctuation">(</span>vocab<span class="token punctuation">[</span><span class="token string">&#39;&lt;unk&gt;&#39;</span><span class="token punctuation">]</span><span class="token punctuation">)</span> <span class="token comment"># 设置默认索引（遇到不认识单词时设置为&lt;unk&gt;）</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>设置文本和标签转换方法 <ul><li>文本转化为对应索引的元组</li><li>标签转化为1和0</li></ul></li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>text_pipeline <span class="token operator">=</span> <span class="token keyword">lambda</span> x<span class="token punctuation">:</span> vocab<span class="token punctuation">(</span>tokenizer<span class="token punctuation">(</span>x<span class="token punctuation">)</span><span class="token punctuation">)</span>
label_pipeline <span class="token operator">=</span> <span class="token keyword">lambda</span> x<span class="token punctuation">:</span> <span class="token builtin">int</span><span class="token punctuation">(</span>x<span class="token operator">==</span><span class="token string">&#39;pos&#39;</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>text_pipeline<span class="token punctuation">(</span><span class="token string">&#39;i love u&#39;</span><span class="token punctuation">)</span><span class="token punctuation">,</span>label_pipeline<span class="token punctuation">(</span><span class="token string">&#39;neg&#39;</span><span class="token punctuation">)</span>
<span class="token operator">-</span><span class="token operator">&gt;</span> <span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">13</span><span class="token punctuation">,</span> <span class="token number">125</span><span class="token punctuation">,</span> <span class="token number">1225</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token number">0</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><code>offset</code> 偏移量（每条评论的起始位置）</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">def</span> <span class="token function">collate_batch</span><span class="token punctuation">(</span>text_label_batch<span class="token punctuation">)</span><span class="token punctuation">:</span>
    label_list<span class="token punctuation">,</span> text_list<span class="token punctuation">,</span> offset_list <span class="token operator">=</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token punctuation">]</span><span class="token punctuation">,</span> <span class="token punctuation">[</span><span class="token number">0</span><span class="token punctuation">]</span>
    <span class="token keyword">for</span> _label<span class="token punctuation">,</span> _text <span class="token keyword">in</span> text_label_batch<span class="token punctuation">:</span>
        label_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>label_pipeline<span class="token punctuation">(</span>_label<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 将标签值映射成数值</span>
        precess_text <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>text_pipeline<span class="token punctuation">(</span>_text<span class="token punctuation">)</span><span class="token punctuation">,</span> dtype<span class="token operator">=</span>torch<span class="token punctuation">.</span>int64<span class="token punctuation">)</span> <span class="token comment"># 将文本映射为索引并转化为tensor</span>
        text_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span>precess_text<span class="token punctuation">)</span>
        offset_list<span class="token punctuation">.</span>append<span class="token punctuation">(</span><span class="token builtin">len</span><span class="token punctuation">(</span>precess_text<span class="token punctuation">)</span><span class="token punctuation">)</span> <span class="token comment"># 将每条评论的长度存为offset</span>
    label_list <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>label_list<span class="token punctuation">)</span>
    text_list <span class="token operator">=</span> torch<span class="token punctuation">.</span>cat<span class="token punctuation">(</span>text_list<span class="token punctuation">)</span>
    offsets <span class="token operator">=</span> torch<span class="token punctuation">.</span>tensor<span class="token punctuation">(</span>offset_list<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">.</span>cumsum<span class="token punctuation">(</span>dim<span class="token operator">=</span><span class="token number">0</span><span class="token punctuation">)</span>
    <span class="token keyword">return</span> label_list<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> text_list<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> offsets<span class="token punctuation">.</span>to<span class="token punctuation">(</span>device<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>初始化加载器（增加参数批次处理函数<code>collate_fn</code>）</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>train_dl <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>train_data<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> shuffle<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">,</span> collate_fn<span class="token operator">=</span>collate_batch<span class="token punctuation">)</span>
test_dl <span class="token operator">=</span> DataLoader<span class="token punctuation">(</span>test_data<span class="token punctuation">,</span> batch_size<span class="token operator">=</span><span class="token number">64</span><span class="token punctuation">,</span> collate_fn<span class="token operator">=</span>collate_batch<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h4 id="创建模型并训练" tabindex="-1"><a class="header-anchor" href="#创建模型并训练" aria-hidden="true">#</a> 创建模型并训练</h4><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">class</span> <span class="token class-name">TextClassificationModel</span><span class="token punctuation">(</span>nn<span class="token punctuation">.</span>Module<span class="token punctuation">)</span><span class="token punctuation">:</span>
    <span class="token keyword">def</span> <span class="token function">__init__</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> vocab_size<span class="token punctuation">,</span> embed_dim<span class="token punctuation">,</span> num_class<span class="token punctuation">)</span><span class="token punctuation">:</span>
        <span class="token builtin">super</span><span class="token punctuation">(</span>TextClassificationModel<span class="token punctuation">,</span> self<span class="token punctuation">)</span><span class="token punctuation">.</span>__init__<span class="token punctuation">(</span><span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>embed_bag <span class="token operator">=</span> nn<span class="token punctuation">.</span>EmbeddingBag<span class="token punctuation">(</span>num_embeddings<span class="token operator">=</span>vocab_size<span class="token punctuation">,</span> embedding_dim<span class="token operator">=</span>embed_dim<span class="token punctuation">)</span>
        self<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>embed_dim<span class="token punctuation">,</span> num_class<span class="token punctuation">)</span>

    <span class="token keyword">def</span> <span class="token function">forward</span><span class="token punctuation">(</span>self<span class="token punctuation">,</span> text<span class="token punctuation">,</span> offset<span class="token punctuation">)</span><span class="token punctuation">:</span>
        embed <span class="token operator">=</span> self<span class="token punctuation">.</span>embed_bag<span class="token punctuation">(</span>text<span class="token punctuation">,</span> offset<span class="token punctuation">)</span>
        out <span class="token operator">=</span> self<span class="token punctuation">.</span>fc<span class="token punctuation">(</span>embed<span class="token punctuation">)</span>
        <span class="token keyword">return</span> out
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>文本分类与图片分类训练过程的不同 <ul><li>文本分类需要将<code>offsets</code>放入模型中</li></ul></li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">def</span> _txt_train<span class="token punctuation">:</span>
    ···
    <span class="token keyword">for</span> label<span class="token punctuation">,</span> text<span class="token punctuation">,</span> offsets <span class="token keyword">in</span> train_dl<span class="token punctuation">:</span>
        label<span class="token punctuation">,</span> text<span class="token punctuation">,</span> offsets <span class="token operator">=</span> label<span class="token punctuation">.</span>to<span class="token punctuation">(</span>self<span class="token punctuation">.</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> text<span class="token punctuation">.</span>to<span class="token punctuation">(</span>self<span class="token punctuation">.</span>device<span class="token punctuation">)</span><span class="token punctuation">,</span> offsets<span class="token punctuation">.</span>to<span class="token punctuation">(</span>self<span class="token punctuation">.</span>device<span class="token punctuation">)</span>
        pred_label <span class="token operator">=</span> model<span class="token punctuation">(</span>text<span class="token punctuation">,</span> offsets<span class="token punctuation">)</span>
        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>pred_label<span class="token punctuation">,</span> label<span class="token punctuation">)</span>
        ···
     ···
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>vocab_size <span class="token operator">=</span> <span class="token builtin">len</span><span class="token punctuation">(</span>vocab<span class="token punctuation">)</span>
embed_dim <span class="token operator">=</span> <span class="token number">100</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>model <span class="token operator">=</span> TextClassificationModel<span class="token punctuation">(</span>vocab_size<span class="token punctuation">,</span> embed_dim<span class="token punctuation">,</span> num_class<span class="token punctuation">)</span>
loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>CrossEntropyLoss<span class="token punctuation">(</span><span class="token punctuation">)</span>
opt <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>SGD<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>
exp_lr_scheduler <span class="token operator">=</span> lr_scheduler<span class="token punctuation">.</span>StepLR<span class="token punctuation">(</span>opt<span class="token punctuation">,</span> step_size<span class="token operator">=</span><span class="token number">7</span><span class="token punctuation">,</span> gamma<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span>
epochs <span class="token operator">=</span> <span class="token number">30</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>train_loss<span class="token punctuation">,</span> train_acc<span class="token punctuation">,</span> test_loss<span class="token punctuation">,</span> test_acc<span class="token punctuation">,</span> best_model_wts <span class="token operator">=</span> common<span class="token punctuation">.</span>ModelTrainer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>txt_fit<span class="token punctuation">(</span>epochs<span class="token punctuation">,</span> train_dl<span class="token punctuation">,</span> test_dl<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> opt<span class="token punctuation">,</span> exp_lr_scheduler<span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div>`,51),o=[e];function c(l,i){return s(),a("div",null,o)}const r=n(p,[["render",c],["__file","简单文本分类与词嵌入表示.html.vue"]]);export{r as default};
