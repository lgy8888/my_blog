import{_ as n}from"./plugin-vue_export-helper-x3n3nnut.js";import{o as s,c as a,f as t}from"./app-OTaO6_y0.js";const p={},e=t(`<h1 id="逻辑回归与交叉熵" tabindex="-1"><a class="header-anchor" href="#逻辑回归与交叉熵" aria-hidden="true">#</a> 逻辑回归与交叉熵</h1><h2 id="sigmoid函数" tabindex="-1"><a class="header-anchor" href="#sigmoid函数" aria-hidden="true">#</a> Sigmoid函数</h2><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20230804194312492.png" alt="image-20230804161804006" tabindex="0" loading="lazy"><figcaption>image-20230804161804006</figcaption></figure><ul><li>Sigmoid函数是一个概率分布函数</li><li>给定某个输出，它将输出为一个概率值</li></ul><h2 id="逻辑回归损失函数" tabindex="-1"><a class="header-anchor" href="#逻辑回归损失函数" aria-hidden="true">#</a> 逻辑回归损失函数</h2><ul><li><p>平方差惩罚的是与损失同一数量级的情形</p></li><li><p>对于分类问题，我们最好的使用交叉熵损失函数会更有效</p></li><li><p>交叉熵会输出一个更大的损失</p></li><li><p>交叉熵刻画的是**实际输出(概率)<strong>和</strong>期望输出(概率)**的距离，也就是交叉熵的值越小，两个概率分布就越接近。</p></li><li><p>概率分布p为期望输出，概率分布q为实际输出，$H(p,q)$为交叉熵，则</p></li></ul><p>$$ H(p,q)=-\\sum_x p(x)logq(x) $$</p><h2 id="逻辑回归案例" tabindex="-1"><a class="header-anchor" href="#逻辑回归案例" aria-hidden="true">#</a> 逻辑回归案例</h2><h3 id="数据预处理" tabindex="-1"><a class="header-anchor" href="#数据预处理" aria-hidden="true">#</a> <strong>数据预处理</strong></h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>data <span class="token operator">=</span> pd<span class="token punctuation">.</span>read_csv<span class="token punctuation">(</span><span class="token string">&#39;./1.基础部分(第1-7章)参考代码和数据集/第4章/credit-a.csv&#39;</span><span class="token punctuation">,</span>header<span class="token operator">=</span><span class="token boolean">None</span><span class="token punctuation">)</span>
<span class="token comment"># 对数据做第一步处理（分出特征值和标签值）</span>
X <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token punctuation">:</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span> <span class="token comment"># 取除了倒数第一列之外的所有列的数据，iloc[行,列]</span>
Y <span class="token operator">=</span> data<span class="token punctuation">.</span>iloc<span class="token punctuation">[</span><span class="token punctuation">:</span><span class="token punctuation">,</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>replace<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">0</span><span class="token punctuation">)</span> <span class="token comment"># 取最后一列的数据，并将-1替换为0</span>
<span class="token comment"># 转换为tensor</span>
X <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>X<span class="token punctuation">.</span>values<span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span>
Y <span class="token operator">=</span> torch<span class="token punctuation">.</span>from_numpy<span class="token punctuation">(</span>Y<span class="token punctuation">.</span>values<span class="token punctuation">.</span>reshape<span class="token punctuation">(</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span><span class="token builtin">type</span><span class="token punctuation">(</span>torch<span class="token punctuation">.</span>float32<span class="token punctuation">)</span> 
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="模型创建" tabindex="-1"><a class="header-anchor" href="#模型创建" aria-hidden="true">#</a> <strong>模型创建</strong></h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>model <span class="token operator">=</span> nn<span class="token punctuation">.</span>Sequential<span class="token punctuation">(</span> <span class="token comment"># 该方法用于将多个层连接在一起</span>
    nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span><span class="token number">15</span><span class="token punctuation">,</span><span class="token number">1</span><span class="token punctuation">)</span><span class="token punctuation">,</span>   <span class="token comment"># 线性层（权重和偏置）</span>
    nn<span class="token punctuation">.</span>Sigmoid<span class="token punctuation">(</span><span class="token punctuation">)</span>       <span class="token comment"># sigmoid层（输出为概率）</span>
<span class="token punctuation">)</span>
loss_fn <span class="token operator">=</span> nn<span class="token punctuation">.</span>BCELoss<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 二元交叉熵损失函数</span>
opt <span class="token operator">=</span> torch<span class="token punctuation">.</span>optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">)</span> <span class="token comment"># Adam优化器</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li><p><code>torch.optim.Adam()</code>是Adam优化器，而<code>torch.optim.SGD()</code>是随机梯度下降（SGD）优化器。</p></li><li><p>区别：</p><ul><li>Adam优化器是一种自适应学习率优化算法，它在不同参数上可以使用不同的学习率，自动调整学习率以加快收敛速度。Adam具有适应性，并且通常对于很多深度学习任务表现良好。</li><li>SGD优化器是传统的随机梯度下降优化算法，它在每个训练步骤中使用相同的学习率来更新所有参数。SGD通常需要手动调整学习率和动量等超参数，而不具备自适应性。</li></ul></li><li><p>Adam优化器不需要人工设置不同参数上的学习率，它是一种自适应学习率优化算法，会自动调整每个参数的学习率。Adam算法会根据每个参数的历史梯度信息来自适应地更新学习率，从而加快收敛速度。</p></li><li><p>设置Adam优化器的学习率仍然是有意义的，虽然它是自适应的，但合理地选择学习率仍能影响训练效果。在使用Adam时，仍然需要进行超参数的调优和学习率的设置，以获得更好的训练结果。</p></li></ul><h3 id="训练" tabindex="-1"><a class="header-anchor" href="#训练" aria-hidden="true">#</a> <strong>训练</strong></h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>batches <span class="token operator">=</span> <span class="token number">16</span> 			<span class="token comment"># batch大小：一次投入16组特征数据进去训练</span>
num_of_batch <span class="token operator">=</span> <span class="token number">653</span><span class="token operator">//</span><span class="token number">16</span>  <span class="token comment"># batch的总数：总数除以单个batch的大小</span>
epoches <span class="token operator">=</span> <span class="token number">1000</span>			<span class="token comment"># 训练1000次</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">for</span> epoch <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>epoches<span class="token punctuation">)</span><span class="token punctuation">:</span>		
    <span class="token keyword">for</span> i <span class="token keyword">in</span> <span class="token builtin">range</span><span class="token punctuation">(</span>num_of_batch<span class="token punctuation">)</span><span class="token punctuation">:</span>	<span class="token comment"># i = 0,1,2...</span>
        start <span class="token operator">=</span> i <span class="token operator">*</span> batches			<span class="token comment"># start = 0*16, 1*16, 2*16 = 0,16,32...</span>
        end <span class="token operator">=</span> start <span class="token operator">+</span> batches		<span class="token comment"># end = 0+16, 16+16, 32+16 = 16,32,48...</span>
        x <span class="token operator">=</span> X<span class="token punctuation">[</span>start<span class="token punctuation">:</span>end<span class="token punctuation">]</span>			<span class="token comment"># 根据batch取出数据</span>
        y <span class="token operator">=</span> Y<span class="token punctuation">[</span>start<span class="token punctuation">:</span>end<span class="token punctuation">]</span>			<span class="token comment"># 根据batch取出标签</span>
        y_pred <span class="token operator">=</span> model<span class="token punctuation">(</span>x<span class="token punctuation">)</span>			<span class="token comment"># 用模型求出预测值</span>
        loss <span class="token operator">=</span> loss_fn<span class="token punctuation">(</span>y_pred<span class="token punctuation">,</span> y<span class="token punctuation">)</span>	<span class="token comment"># 用预测值和真实值求出损失</span>
        opt<span class="token punctuation">.</span>zero_grad<span class="token punctuation">(</span><span class="token punctuation">)</span>				<span class="token comment"># 梯度清零</span>
        loss<span class="token punctuation">.</span>backward<span class="token punctuation">(</span><span class="token punctuation">)</span>				<span class="token comment"># 计算梯度 反向传播</span>
        opt<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>					<span class="token comment"># 参数优化</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h3 id="评价" tabindex="-1"><a class="header-anchor" href="#评价" aria-hidden="true">#</a> <strong>评价</strong></h3><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>model<span class="token punctuation">.</span>state_dict<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># sigmoid(w1*x1 + w2*x2 + … + w15*x15 + b)</span>
<span class="token operator">-</span><span class="token operator">&gt;</span> OrderedDict<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">(</span><span class="token string">&#39;0.weight&#39;</span><span class="token punctuation">,</span>
              tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1.5017e-01</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.4289e-02</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.4474e-04</span><span class="token punctuation">,</span>  <span class="token number">1.7337e-01</span><span class="token punctuation">,</span>  <span class="token number">1.8436e-01</span><span class="token punctuation">,</span>
                       <span class="token operator">-</span><span class="token number">2.0531e-02</span><span class="token punctuation">,</span>  <span class="token number">1.8206e-01</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.3951e-01</span><span class="token punctuation">,</span>  <span class="token number">2.8131e+00</span><span class="token punctuation">,</span>  <span class="token number">3.2382e-01</span><span class="token punctuation">,</span>
                       <span class="token operator">-</span><span class="token number">1.6637e-01</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">1.7796e-01</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">6.7890e-02</span><span class="token punctuation">,</span>  <span class="token number">7.4408e-04</span><span class="token punctuation">,</span> <span class="token operator">-</span><span class="token number">3.3554e-04</span><span class="token punctuation">]</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">,</span>
             <span class="token punctuation">(</span><span class="token string">&#39;0.bias&#39;</span><span class="token punctuation">,</span> tensor<span class="token punctuation">(</span><span class="token punctuation">[</span><span class="token number">0.1143</span><span class="token punctuation">]</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">]</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>acc <span class="token operator">=</span> <span class="token punctuation">(</span><span class="token punctuation">(</span>model<span class="token punctuation">(</span>X<span class="token punctuation">)</span><span class="token punctuation">.</span>data<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token operator">&gt;</span> <span class="token number">0.5</span><span class="token punctuation">)</span><span class="token punctuation">.</span>astype<span class="token punctuation">(</span><span class="token string">&#39;int&#39;</span><span class="token punctuation">)</span> <span class="token operator">==</span> Y<span class="token punctuation">.</span>numpy<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">)</span><span class="token punctuation">.</span>mean<span class="token punctuation">(</span><span class="token punctuation">)</span> <span class="token comment"># 预测值(0/1)与真实值(0/1)的均值</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div>`,19),o=[e];function c(l,u){return s(),a("div",null,o)}const k=n(p,[["render",c],["__file","逻辑回归与交叉熵.html.vue"]]);export{k as default};
