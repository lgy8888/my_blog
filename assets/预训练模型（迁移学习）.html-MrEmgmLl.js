import{_ as n}from"./plugin-vue_export-helper-x3n3nnut.js";import{o as a,c as s,f as e}from"./app-OTaO6_y0.js";const t={},p=e(`<h1 id="预训练模型-迁移学习" tabindex="-1"><a class="header-anchor" href="#预训练模型-迁移学习" aria-hidden="true">#</a> 预训练模型（迁移学习）</h1><h2 id="预训练模型" tabindex="-1"><a class="header-anchor" href="#预训练模型" aria-hidden="true">#</a> 预训练模型</h2><h3 id="预训练网络" tabindex="-1"><a class="header-anchor" href="#预训练网络" aria-hidden="true">#</a> 预训练网络</h3><ul><li>如果这个原始数据集足够大且足够通用，那么与预训练网络学到的特征的空间层次结构可以作为有效的提取视觉世界特征的模型</li><li>即使新问题和新任务与原始任务完全不同</li><li>学习到的特征在不同问题之间是可移植的，这也是深度学习之于浅度学习的优势。它使得深度学习对于小数据问题非常的有效</li></ul><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20230810110042659.png" alt="image-20230810191527845" tabindex="0" loading="lazy"><figcaption>image-20230810191527845</figcaption></figure><ul><li>分类器 -&gt; 全连接层</li><li>卷积基 -&gt; 卷积层</li><li>使用预训练模型的训练过程中只改变分类器的参数</li></ul><h4 id="pytorch内置的预训练网络" tabindex="-1"><a class="header-anchor" href="#pytorch内置的预训练网络" aria-hidden="true">#</a> pytorch内置的预训练网络</h4><p>VGG16、VGG19、densenet、ResNet、mobilenet、Inception v3、Xception等经典的模型架构</p><h3 id="imagenet" tabindex="-1"><a class="header-anchor" href="#imagenet" aria-hidden="true">#</a> ImageNet</h3><ul><li>是一个手动标注好类别的图片数据库（为了机器视觉研究）</li><li>目前已经有22000个类别</li></ul><h5 id="imagenet视觉识别比赛-ilsvrc" tabindex="-1"><a class="header-anchor" href="#imagenet视觉识别比赛-ilsvrc" aria-hidden="true">#</a> ImageNet视觉识别比赛（ILSVRC）</h5><ul><li>这个比赛是训练一个模型，能够将输入图片正确分类到1000个类别中的某个类别</li><li>训练集120万，验证集5万，测试集10万</li><li>在图像分类方面，ImageNet比赛准确率已经作为计算机视觉分类算法的基准</li><li>自2012年以来，卷积神经网络和深度学习技术主导了这一比赛的排行榜</li></ul><h3 id="vgg" tabindex="-1"><a class="header-anchor" href="#vgg" aria-hidden="true">#</a> VGG</h3><h4 id="vgg定义及架构" tabindex="-1"><a class="header-anchor" href="#vgg定义及架构" aria-hidden="true">#</a> VGG定义及架构</h4><ul><li><p>VGG（VisualGeometryGroup）：属于牛津大学科学工程系，其发布了一系列以VGG开头的卷积网络模型，可以应用在人脸识别，图像分类等方面，分别从VGG16~VGG19</p></li><li><p>VGG研究卷积网络深度的初衷是想搞清楚<strong>卷积网络深度</strong>是如何影响大规模图像分类与<strong>识别精度和准确率</strong>的</p></li><li><p>VGG模型结构简单有效，前几层仅使用3*3卷积核来增加网络深度，通过maxpooling（最大池化）依次减少每层神经元数量，最后三层分别是2个有4096个神经元的全连接层和一个softmax层</p></li><li><p>VGG在加深网络层数的同时为了避免参数过多，在所有层都采用3*3的小卷积核，步长设置为1</p></li></ul><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20230811153820004.png" alt="image-20230810155323023" tabindex="0" loading="lazy"><figcaption>image-20230810155323023</figcaption></figure><ul><li>conv：卷积层</li><li>FC：全连接层</li><li>conv3：3*3卷积核的卷积层</li><li>conv3-64：深度为64</li><li>maxpooling：最大池化</li></ul><figure><img src="http://lgy-markdown-img.oss-cn-guangzhou.aliyuncs.com/image/image-20230810155323023.png" alt="image-20230810155539827" tabindex="0" loading="lazy"><figcaption>image-20230810155539827</figcaption></figure><ul><li>实际处理中可以对第一个全连接层改为7*7的卷积网络，后面两个全连接层改为1*1的卷积网络，这个整个VGG就变成一个全卷积网络FCN</li></ul><h4 id="vgg的缺点" tabindex="-1"><a class="header-anchor" href="#vgg的缺点" aria-hidden="true">#</a> VGG的缺点</h4><ul><li>网络结构weight数量相当大，很消耗磁盘空间</li><li>训练非常慢</li><li>由于其全连接结点的数量较多，再加上网络比较深，VGG16有533MB+，VGG19有574MB，这使得部署VGG比较耗时</li></ul><h2 id="vgg实现" tabindex="-1"><a class="header-anchor" href="#vgg实现" aria-hidden="true">#</a> VGG实现</h2><ul><li>导入模型</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>vgg16<span class="token punctuation">(</span>weights<span class="token operator">=</span>VGG16_Weights<span class="token punctuation">.</span>IMAGENET1K_V1<span class="token punctuation">,</span> progress<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>VGG(
  (features): Sequential(
    (0): Conv2d(3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
    (1): ReLU(inplace=True)
    (2): Conv2d(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1))
	···
    (29): ReLU(inplace=True)
    (30): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)
  )
  (avgpool): AdaptiveAvgPool2d(output_size=(7, 7))
  (classifier): Sequential(
    (0): Linear(in_features=25088, out_features=4096, bias=True)
    (1): ReLU(inplace=True)
	···
    (5): Dropout(p=0.5, inplace=False)
    (6): Linear(in_features=4096, out_features=1000, bias=True)
  )
)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>冻结卷积基</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">for</span> p <span class="token keyword">in</span> model<span class="token punctuation">.</span>features<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    p<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span>  <span class="token comment"># 冻结卷积基</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>修改分类器</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>model<span class="token punctuation">.</span>classifier<span class="token punctuation">[</span><span class="token operator">-</span><span class="token number">1</span><span class="token punctuation">]</span><span class="token punctuation">.</span>out_features <span class="token operator">=</span> <span class="token number">4</span>  <span class="token comment"># 修改分类器</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h2 id="数据增强" tabindex="-1"><a class="header-anchor" href="#数据增强" aria-hidden="true">#</a> 数据增强</h2><ul><li><p>人为的扩增数据</p></li><li><p>通过改变原图（拉伸，裁剪，反转，色度……）</p></li><li><p>使用<code>transforms</code>对数据进行增强</p></li><li><p>数据增强可以抑制模型过拟合，提高泛化度</p></li></ul><p><strong>数据增强方法</strong></p><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>transforms<span class="token punctuation">.</span>RandomResizedCrop<span class="token punctuation">(</span><span class="token punctuation">)</span> 						<span class="token comment"># 随机位置裁剪</span>
transforms<span class="token punctuation">.</span>CenterCrop<span class="token punctuation">(</span><span class="token punctuation">)</span> 							<span class="token comment"># 中间位置裁剪</span>
transforms<span class="token punctuation">.</span>RandomHorizontalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span>					<span class="token comment"># 随机水平翻转</span>
transforms<span class="token punctuation">.</span>RandomVerticalFlip<span class="token punctuation">(</span><span class="token punctuation">)</span>						<span class="token comment"># 随机上下翻转</span>
transforms<span class="token punctuation">.</span>RandomRotation<span class="token punctuation">(</span><span class="token punctuation">)</span>							<span class="token comment"># 随机旋转</span>
torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ColorJitter<span class="token punctuation">(</span>brightness<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span> 	<span class="token comment"># 随机明暗度</span>
torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ColorJitter<span class="token punctuation">(</span>contract<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>		<span class="token comment"># 随机对比度</span>
torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ColorJitter<span class="token punctuation">(</span>saturation<span class="token operator">=</span><span class="token number">1</span><span class="token punctuation">)</span>	<span class="token comment"># 随机饱和度</span>
torchvision<span class="token punctuation">.</span>transforms<span class="token punctuation">.</span>ColorJitter<span class="token punctuation">(</span>hue<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>			<span class="token comment"># 随机颜色</span>
torchvision<span class="token punctuation">.</span>RandomGrayscale<span class="token punctuation">(</span>p<span class="token operator">=</span><span class="token number">0.5</span><span class="token punctuation">)</span>					<span class="token comment"># 随机灰度化</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="学习速率衰减" tabindex="-1"><a class="header-anchor" href="#学习速率衰减" aria-hidden="true">#</a> 学习速率衰减</h2><ul><li>导入<code>lr_scheduler</code></li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">from</span> torch<span class="token punctuation">.</span>optim <span class="token keyword">import</span> lr_scheduler
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><ul><li>创建学习速率衰减器</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>lr_scheduler<span class="token punctuation">.</span>StepLR<span class="token punctuation">(</span>opt<span class="token punctuation">,</span> step_size<span class="token operator">=</span><span class="token number">5</span><span class="token punctuation">,</span> gamma<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span> <span class="token comment"># 根据步数进行衰减(每5个epoch衰减一次)，gamma为衰减率</span>
lr_scheduler<span class="token punctuation">.</span>MultiStepLR<span class="token punctuation">(</span>opt<span class="token punctuation">,</span> milestones<span class="token operator">=</span><span class="token punctuation">[</span><span class="token number">20.</span> <span class="token number">50</span><span class="token punctuation">,</span> <span class="token number">80</span><span class="token punctuation">]</span><span class="token punctuation">,</span> gamma<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span> <span class="token comment"># 根据里程进行衰减(在epoch=20,50,80的时候衰减)</span>
lr_scheduler<span class="token punctuation">.</span>ExponentialLR<span class="token punctuation">(</span>opt<span class="token punctuation">,</span> gamma<span class="token operator">=</span><span class="token number">0.1</span><span class="token punctuation">)</span> <span class="token comment"># 每一个epoch都进行衰减</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>将衰减器放进训练中（一次训练衰减一次）</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>lr_scheduler<span class="token punctuation">.</span>step<span class="token punctuation">(</span><span class="token punctuation">)</span>  <span class="token comment"># 学习速率衰减</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><h2 id="resnet实现" tabindex="-1"><a class="header-anchor" href="#resnet实现" aria-hidden="true">#</a> ResNet实现</h2><ul><li>导入<code>ResNet18</code>预训练模型</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>model <span class="token operator">=</span> torchvision<span class="token punctuation">.</span>models<span class="token punctuation">.</span>resnet18<span class="token punctuation">(</span>weights<span class="token operator">=</span>ResNet18_Weights<span class="token punctuation">.</span>IMAGENET1K_V1<span class="token punctuation">,</span> progress<span class="token operator">=</span><span class="token boolean">True</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div></div></div><div class="language-text line-numbers-mode" data-ext="text"><pre class="language-text"><code>ResNet(
	···
	(parameters)
	···
	(avgpool): AdaptiveAvgPool2d(output_size=(1, 1))
  	(fc): Linear(in_features=512, out_features=1000, bias=True)
)
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>冻结所有参数</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">for</span> p <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    p<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">False</span>  <span class="token comment"># 冻结参数</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>自定义fc层替换原有的fc层</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>in_features <span class="token operator">=</span> model<span class="token punctuation">.</span>fc<span class="token punctuation">.</span>in_features
model<span class="token punctuation">.</span>fc <span class="token operator">=</span> nn<span class="token punctuation">.</span>Linear<span class="token punctuation">(</span>in_features<span class="token punctuation">,</span> <span class="token number">4</span><span class="token punctuation">)</span> <span class="token comment"># 替换fc层</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><h2 id="微调" tabindex="-1"><a class="header-anchor" href="#微调" aria-hidden="true">#</a> 微调</h2><h3 id="定义" tabindex="-1"><a class="header-anchor" href="#定义" aria-hidden="true">#</a> 定义</h3><ul><li><p>共同训练新添加的分类器层和部分或全部卷积层</p></li><li><p>这允许我们微调基础模型中的高阶特征表示，以使它们与特定任务更相关</p></li><li><p>只有分类器已经训练好了，才能微调卷积基的卷积层</p></li><li><p>如果没有这样的话，刚开始的训练误差很大，微调之前这些卷积层学到的表示会被破坏掉</p></li></ul><h3 id="微调步骤" tabindex="-1"><a class="header-anchor" href="#微调步骤" aria-hidden="true">#</a> 微调步骤</h3><ol><li>在预训练卷积基上添加自定义层</li><li>冻结卷积基所有层</li><li>训练添加的分类层</li><li>解冻卷积基的一部分层</li><li>联合训练解冻的卷积层和添加的自定义层</li></ol><h3 id="微调resnet101" tabindex="-1"><a class="header-anchor" href="#微调resnet101" aria-hidden="true">#</a> 微调ResNet101</h3><ul><li>开放所有的卷积层</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code><span class="token keyword">for</span> param <span class="token keyword">in</span> model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">:</span>
    param<span class="token punctuation">.</span>requires_grad <span class="token operator">=</span> <span class="token boolean">True</span> <span class="token comment"># 开放所有卷积层进行微调</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>设置微调的epochs和优化器</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>extend_epochs <span class="token operator">=</span> <span class="token number">20</span>
opt <span class="token operator">=</span> optim<span class="token punctuation">.</span>Adam<span class="token punctuation">(</span>model<span class="token punctuation">.</span>parameters<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">,</span> lr<span class="token operator">=</span><span class="token number">0.0001</span><span class="token punctuation">)</span> <span class="token comment"># 微调时训练的速率应设置小一点</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>进行微调训练</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>extend_train_loss<span class="token punctuation">,</span> extend_train_acc<span class="token punctuation">,</span> extend_test_loss<span class="token punctuation">,</span> extend_test_acc <span class="token operator">=</span> \\
    common<span class="token punctuation">.</span>ModelTrainer<span class="token punctuation">(</span><span class="token punctuation">)</span><span class="token punctuation">.</span>fit<span class="token punctuation">(</span>extend_epochs<span class="token punctuation">,</span> train_dl<span class="token punctuation">,</span> test_dl<span class="token punctuation">,</span> model<span class="token punctuation">,</span> loss_fn<span class="token punctuation">,</span> opt<span class="token punctuation">,</span> exp_lr_scheduler<span class="token punctuation">)</span>

train_loss <span class="token operator">+=</span> extend_train_loss
train_acc <span class="token operator">+=</span> extend_train_acc
test_loss <span class="token operator">+=</span> extend_test_loss
test_acc <span class="token operator">+=</span> extend_test_acc

epochs <span class="token operator">+=</span> extend_epochs
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div><ul><li>绘图查看微调后模型的损失和准确率</li></ul><div class="language-python line-numbers-mode" data-ext="py"><pre class="language-python"><code>plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">,</span> train_loss<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">&#39;train_loss&#39;</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>epochs<span class="token punctuation">)</span><span class="token punctuation">,</span> test_loss<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">&#39;test_loss&#39;</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>

plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>epochs <span class="token operator">+</span> extend_epochs<span class="token punctuation">)</span><span class="token punctuation">,</span> train_acc<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">&#39;train_acc&#39;</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>plot<span class="token punctuation">(</span><span class="token builtin">range</span><span class="token punctuation">(</span>epochs <span class="token operator">+</span> extend_epochs<span class="token punctuation">)</span><span class="token punctuation">,</span> test_acc<span class="token punctuation">,</span> label<span class="token operator">=</span><span class="token string">&#39;test_acc&#39;</span><span class="token punctuation">)</span>
plt<span class="token punctuation">.</span>legend<span class="token punctuation">(</span><span class="token punctuation">)</span>
</code></pre><div class="line-numbers" aria-hidden="true"><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div><div class="line-number"></div></div></div>`,62),i=[p];function o(l,c){return a(),s("div",null,i)}const d=n(t,[["render",o],["__file","预训练模型（迁移学习）.html.vue"]]);export{d as default};
